Title,Abstract
IFaaSBus: A Security- and Privacy-Based Lightweight Framework for Serverless Computing Using IoT and Machine Learning,"As data of COVID-19 patients is increasing, the new framework is required to secure the data collected from various Internet of Things (IoT) devices and predict the trend of disease to reduce its spreading. This article proposes security- and privacy-based lightweight framework called iFaaSBus, which uses the concept of IoT, machine learning (ML), and function as a service (FaaS) or serverless computing to diagnose the COVID-19 disease and manages resources automatically to enable dynamic scalability. iFaaSBus offers OAuth-2.0 Authorization protocol-based privacy and JSON Web Token & Transport Layer Socket protocol-based security to secure the patient's health data. iFaaSBus outperforms response time compared to nonserverless computing while responding to up to 1100 concurrent requests. Further, the performance of various ML models is evaluated based on accuracy, precision, recall, F-score, and area under the curve (AUC) values, and the K-nearest neighbor model gives the highest accuracy rate of 97.51%. © 2005-2012 IEEE."
Reinforcement learning-assisted autoscaling mechanisms for serverless computing platforms,"Serverless computing is emerging as a cloud computing paradigm that provisions computing resources on demand, while billing is taking place based on the exact usage of the cloud resources. The responsibility for infrastructure management is undertaken by cloud providers, enabling developers to focus on the development of the business logic of their applications. For managing scalability, various autoscaling mechanisms have been proposed that try to optimize the provisioning of resources based on the posed workload. These mechanisms are configured and managed by the cloud provider, imposing non negligible administration overhead. A set of challenges are identified for introducing automation and optimizing the provisioning of resources, while in parallel respecting the agreed Service Level Agreement between cloud and application providers. To address these challenges, we have developed autoscaling mechanisms for serverless applications that are powered by Reinforcement Learning (RL) techniques. A set of RL environments and agents have been implemented (based on Q-learning, DynaQ+ and Deep Q-learning algorithms) for driving autoscaling mechanisms, able to autonomously manage dynamic workloads with Quality of Service (QoS) guarantees, while opting for efficient usage of resources. The produced environments and agents are evaluated in real and simulated environments, taking advantage of the Kubeless open-source serverless platform. The evaluation results validate the suitability of the proposed mechanisms to efficiently tackle scalability management for serverless applications. © 2022 Elsevier B.V."
Serverless Computing Approach for Deploying Machine Learning Applications in Edge Layer,"Serverless computing-a stateless cloud computing model, is an emerging solution that has shown significant benefits to efficiency and cost for event-driven applications in the cloud environment, including artificial intelligence (AI), machine learning applications. With serverless computing, the machine learning system's complexity is minimized, flexible and straightforward in management. However, operating and managing serverless machine learning services on clouds faces many limitations such as latency and data privacy. Local distributed edge computing nodes which are closed to users can address these challenges of cloud-serverless AI applications. Based on this motivation, in this paper, we propose an architecture for deploying machine learning workload as serverless functions in the edge environment. We illustrate our proposed approach and evaluate its performance and effectiveness by exploiting a holistic end-to-end image classifier, a famous machine learning use case in the MNIST dataset. Our proof of concept provides comprehensive assessments that prove its effectiveness in latency reduction and distributed machine learning deployment. © 2022 IEEE."
A Machine Learning-Based Approach for Efficient Cloud Service Selection,"Cloud computing can be considered a revolutionizing invention of decay. The computing resources are externally supplied to the user with benefits of scalability, accessibility, pay-as-you-go, serverless, etc. With its ever-growing market, there is a multitude of cloud service providers (CSPs) with different offerings available to small and medium enterprises (SMEs) or users. Due to the availability of numerous CSPs with different offerings, it becomes complicated for the user to pick the right services. In the presented paper, a supervised learning-based model based on Random Forest Regressor is proposed. The proposed model has been trained for Multi Criteria Decision Making Methods (MCDM) methods such as Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS), VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR), and Weighted Sum Method (WSM). The score obtained from these MCDM methods has been used to rank the services. Results show the acceptability of the proposed model in the cloud environment. © 2022, Springer Nature Switzerland AG."
Federated Learning with Cooperating Devices: A Consensus Approach,"Federated learning (FL) is arising as another perspective to prepare AI models (machine learning) in conveyed frameworks. Rather than sharing and uncovering the readiness educational record with the specialist, the model limits (e.g., neural associations tendencies) progress in all things considered by very large masses of interconnections, appearing as neighborhood understudies. FL can be applied to control obligated Internet of Things (IoT) devices with moderate and conflicting affiliations. Also, it need not waste time with data to be exchanged with unusable matters, saving security. Despite these advantages, an essential restriction of existing systems is to merge improvements, which depends upon an expert for total and blend of nearby restricts; this has the weight of a solitary inspiration driving disappointment and scaling issues for developing association size. This article proposes a completely flowed (or serverless) learning approach: the proposed FL calculations sway the premium of gadgets that perform information practices inside the relationship by reiterating nearby assessments and standard relationships through plan-based procedures. The technique places the justification for the trade-off of FL inside 5G and past affiliations portrayed by the decentralized association and planning, with information flow over the end gadgets. The proposed methodology is checked by the exploratory instructive records collected inside an ndustrial IoT (IIoT) condition. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG."
"Proceedings of the 8th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies, BDCAT 2021",The proceedings contain 15 papers. The topics discussed include: evaluating serverless architecture for big data enterprise applications; 3D object recognition for virtual reality based digital twins; linking user accounts across social media platforms; crowd counting using deep learning in edge devices; multiscale clustering based diffusion representation learning method; a proactive data-parallel framework for machine learning; distributed orchestration of regression models over administrative boundaries; attribute network embedding method based on joint clustering of representation and network; and comparative analysis of pre-trained deep neural networks for vision-based security systems on a novel dataset.
"Proceedings of the 7th International Workshop on Serverless Computing, WoSC 2021",The proceedings contain 7 papers. The topics discussed include: is function-as-a-service a good fit for latency-critical services?; BIAS Autoscaler: leveraging burstable instances for cost-effective autoscaling on cloud systems; implications of alternative serverless application control flow methods; beyond @cloudfunction: powerful code annotations to capture serverless runtime patterns; SFL: a compiler for generating stateful AWS lambda serverless applications; SLA for sequential serverless chains: a machine learning approach; and towards demystifying intra-function parallelism in serverless computing.
SLA for Sequential Serverless Chains: A Machine Learning Approach,"Despite its vast potential, a challenge facing serverless computing's wide-scale adoption is the lack of Service Level Agreements (SLAs) for serverless platforms. This challenge is compounded when composition technologies are employed to construct large applications using chains of functions. Due to the dependency of a chain's performance on each function forming it, a single function's sub-optimal performance can result in performance degradations of the entire chain. This paper sheds light on this problem and provides a categorical classification of the factors that impact a serverless function execution performance. We discuss the challenge of serverless chains' SLA and present the results of leveraging FaaS2F, our proposed serverless SLA framework, to define SLAs for fixed-size and variable-size sequential serverless chains. The validation results demonstrate high accuracy in detecting sub-optimal executions exceeding 79%. © 2021 ACM."
GNOSIS-query-driven multimodal event processing for unstructured data streams,"This paper presents GNOSIS, an event processing engine to detect complex event patterns over multimodal data streams. GNOSIS follows a query-driven approach where users can write complex event queries using Multimodal Event Processing Language (MEPL). The system models incoming multimodal data into an evolving Multimodal Event Knowledge Graph (MEKG) using an ensemble of deep neural network (DNN) and machine learning (ML) models and applies a neuro-symbolic approach for event matching. GNOSIS follows a serverless paradigm where its different components act as independent microservices and can be deployed across different nodes with optimized edge support. The paper demonstrates two multimodal use case queries from Occupational Health and Safety and Accessibility domain. © 2021 Owner/Author."
A TinyML Platform for On-Device Continual Learning with Quantized Latent Replays,"In the last few years, research and development on Deep Learning models & techniques for ultra-low-power devices- in a word, TinyML - has mainly focused on a train-then-deploy assumption, with static models that cannot be adapted to newly collected data without cloud-based data collection and fine-tuning. Latent Replay-based Continual Learning (CL) techniques (Pellegrini et al., 2020) enable online, serverless adaptation in principle, but so far they have still been too computation- and memory-hungry for ultra-low-power TinyML devices, which are typically based on microcontrollers. In this work, we introduce a HW/SW platform for end-to-end CL based on a 10-core FP32 -enabled parallel ultra-low-power (PULP) processor. We rethink the baseline Latent Replay CL algorithm, leveraging quantization of the frozen stage of the model and Latent Replays (LRs) to reduce their memory cost with minimal impact on accuracy. In particular, 8-bit compression of the LR memory proves to be almost lossless (-0.26% with 3000LR) compared to the full-precision baseline implementation, but requires 4times less memory, while 7-bit can also be used with an additional minimal accuracy degradation (up to 5%). We also introduce optimized primitives for forward and backward propagation on the PULP processor, together with data tiling strategies to fully exploit its memory hierarchy, while maximizing efficiency. Our results show that by combining these techniques, continual learning can be achieved in practice using less than 64MB of memory - an amount compatible with embedding in TinyML devices. On an advanced 22nm prototype of our platform, called VEGA, the proposed solution performs on average 65 times faster than a low-power STM32 L4 microcontroller, being 37times more energy efficient - enough for a lifetime of 535h when learning a new mini-batch of data once every minute. © 2011 IEEE."
Scheduling Hardware-Accelerated Cloud Functions,"This paper presents a Function-as-a-Service (FaaS) approach for deploying managed cloud functions onto heterogeneous cloud infrastructures. Current FaaS systems, such as AWS Lambda, allow domain-specific functionality, such as AI, HPC and image processing, to be deployed in the cloud while abstracting users from infrastructure and platform concerns. Existing approaches, however, use a single type of resource configuration to execute all function requests. In this paper, we present a novel FaaS approach that allows cloud functions to be effectively executed across heterogeneous compute resources, including hardware accelerators such as GPUs and FPGAs. We implement heterogeneous scheduling to tailor resource selection to each request, taking into account performance and cost concerns. In this way, our approach makes use of different processor types and quantities (e.g. 2 CPU cores), uniquely suited to handle different types of workload, potentially providing improved performance at a reduced cost. We validate our approach in three application domains: machine learning, bio-informatics, and physics, and target a hardware platform with a combined computational capacity of 24 FPGAs and 12 CPU cores. Compared to traditional FaaS, our approach achieves a cost improvement for non-uniform traffic of up to 8.9 times, while maintaining performance objectives. © 2021, The Author(s)."
"Proceedings of SC 2021: The International Conference for High Performance Computing, Networking, Storage and Analysis: Science and Beyond","The proceedings contain 105 papers. The topics discussed include: tensor processing primitives: a programming abstraction for efficiency and portability in deep learning workloads; enable simultaneous DNN services based on deterministic operator overlap and precise latency prediction; preparing an incompressible-flow fluid dynamics code for exascale-class wind energy simulations; a next-generation discontinuous Galerkin fluid dynamics solver with application to high-resolution lung airflow simulations; understanding, predicting and scheduling serverless workloads under partial interference; the hidden cost of the edge: a performance comparison of edge and cloud latencies; ribbon: cost-effective and QoS-aware deep learning model inference using a diverse pool of cloud computing instances; and chimera: efficiently training large-scale neural networks with bidirectional pipelines."
"12th Annual ACM Symposium on Cloud Computing, SoCC 2021","The proceedings contain 46 papers. The topics discussed include: Lorien: efficient deep learning workloads delivery; elastic hyperparameter tuning on the cloud; siren: byzantine-robust federated learning via proactive alarming; automating instrumentation choices for performance problems in distributed applications with VAIF; tprof: performance profiling via structural aggregation and automated analysis of distributed systems traces; cloud-scale runtime verification of serverless applications; building reliable cloud services using coyote actors; atoll: a scalable low-latency serverless platform; kraken : adaptive container provisioning for deploying dynamic DAG applications in serverless platforms; and Mu: an efficient, fair and responsive serverless framework for resource-constrained edge clouds."
You Do Not Need a bigger boat: Recommendations at Reasonable Scale in a (Mostly) serverless and open stack,"We argue that immature data pipelines are preventing a large portion of industry practitioners from leveraging the latest research on recommender systems. We propose our template data stack for machine learning at ""reasonable scale"", and show how many challenges are solved by embracing a serverless paradigm. Leveraging our experience, we detail how modern open source tools can provide a pipeline processing terabytes of data with minimal infrastructure work. © 2021 Owner/Author."
Enhancing automated FaaS with cost-aware provisioning of cloud resources,"Compute resources are becoming more diverse, more specialized, and more physically distributed every day. To properly use these resources, the new paradigm of serverless computing aims to abstract away the complexity associated with resource configuration and workload deployment. Building on this serverless architecture are efforts for automated resource selection and automated task distribution and coordination. As computing resources advance, so too does application-specific optimizations, as is the case of deep learning on GPUs or even the more specialized TPUs. To better navigate the efficient and effective use of these diverse resources, we present the addition of automated, cost-aware provisioning of cloud resources to a state-of-the-art automated serverless framework. By automating the selection, provisioning, and configuration of cloud resources, our framework, which we call DELTA+, will enable truly cost-aware usage of the cloud by navigating complex computational tradeoffs. In this proposal, we will outline how we plan to introduce burstable cloud computing to automated serverless infrastructure and to present our initial findings with respect to system design and performance. © 2021 IEEE."
Serverless Workflows for Containerised Applications in the Cloud Continuum,"This paper introduces an open-source platform to support serverless computing for scientific data-processing workflow-based applications across the Cloud continuum (i.e. simultaneously involving both on-premises and public Cloud platforms to process data captured at the edge). This is achieved via dynamic resource provisioning for FaaS platforms compatible with scale-to-zero approaches that minimise resource usage and cost for dynamic workloads with different elasticity requirements. The platform combines the usage of dynamically deployed auto-scaled Kubernetes clusters on on-premises Clouds and automated Cloud bursting into AWS Lambda to achieve higher levels of elasticity. A use case in public health for smart cities is used to assess the platform, in charge of detecting people not wearing face masks from captured videos. Faces are blurred for enhanced anonymity in the on-premises Cloud and detection via Deep Learning models is performed in AWS Lambda for this data-driven containerised workflow. The results indicate that hybrid workflows across the Cloud continuum can efficiently perform local data processing for enhanced regulations compliance and perform Cloud bursting for increased levels of elasticity. © 2021, The Author(s)."
Edge-adaptable serverless acceleration for machine learning Internet of Things applications,"Serverless computing is an emerging event-driven programming model that accelerates the development and deployment of scalable web services on cloud computing systems. Though widely integrated with the public cloud, serverless computing use is nascent for edge-based, Internet of Things (IoT) deployments. In this work, we present STOIC (serverless teleoperable hybrid cloud), an IoT application deployment and offloading system that extends the serverless model in three ways. First, STOIC adopts a dynamic feedback control mechanism to precisely predict latency and dispatch workloads uniformly across edge and cloud systems using a distributed serverless framework. Second, STOIC leverages hardware acceleration (e.g., GPU resources) for serverless function execution when available from the underlying cloud system. Third, STOIC can be configured in multiple ways to overcome deployment variability associated with public cloud use. We overview the design and implementation of STOIC and empirically evaluate it using real-world machine learning applications and multitier IoT deployments (edge and cloud). Specifically, we show that STOIC can be used for training image processing workloads (for object recognition)—once thought too resource-intensive for edge deployments. We find that STOIC reduces overall execution time (response latency) and achieves placement accuracy that ranges from 92% to 97%. © 2020 John Wiley & Sons, Ltd."
An empirical study on challenges of application development in serverless computing,"Serverless computing is an emerging paradigm for cloud computing, gaining traction in a wide range of applications such as video processing and machine learning. This new paradigm allows developers to focus on the development of the logic of serverless computing based applications (abbreviated as serverless-based applications) in the granularity of function, thereby freeing developers from tedious and error-prone infrastructure management. Meanwhile, it also introduces new challenges on the design, implementation, and deployment of serverless-based applications, and current serverless computing platforms are far away from satisfactory. However, to the best of our knowledge, these challenges have not been well studied. To fill this knowledge gap, this paper presents the first comprehensive study on understanding the challenges in developing serverless-based applications from the developers' perspective. We mine and analyze 22,731 relevant questions from Stack Overflow (a popular Q&A website for developers), and show the increasing popularity trend and the high difficulty level of serverless computing for developers. Through manual inspection of 619 sampled questions, we construct a taxonomy of challenges that developers encounter, and report a series of findings and actionable implications. Stakeholders including application developers, researchers, and cloud providers can leverage these findings and implications to better understand and further explore the serverless computing paradigm. © 2021 ACM."
AMPS-Inf: Automatic Model Partitioning for Serverless Inference with Cost Efficiency,"The salient pay-per-use nature of serverless computing has driven its continuous penetration as an alternative computing paradigm for various workloads. Yet, challenges arise and remain open when shifting machine learning workloads to the serverless environment. Specifically, the restriction on the deployment size over serverless platforms combining with the complexity of neural network models makes it difficult to deploy large models in a single serverless function. In this paper, we aim to fully exploit the advantages of the serverless computing paradigm for machine learning workloads targeting at mitigating management and overall cost while meeting the response-time Service Level Objective (SLO). We design and implement AMPS-Inf, an autonomous framework customized for model inferencing in serverless computing. Driven by the cost-efficiency and timely-response, our proposed AMPS-Inf automatically generates the optimal execution and resource provisioning plans for inference workloads. The core of AMPS-Inf relies on the formulation and solution of a Mixed-Integer Quadratic Programming problem for model partitioning and resource provisioning with the objective of minimizing cost without violating response time SLO. We deploy AMPS-Inf on the AWS Lambda platform, evaluate with the state-of-the-art pre-trained models in Keras including ResNet50, Inception-V3 and Xception, and compare with Amazon SageMaker and three baselines. Experimental results demonstrate that AMPS-Inf achieves up to 98% cost saving without degrading response time performance. © 2021 ACM."
A Scalable Cloud-based Architecture to Deploy JupyterHub for Computational Social Science Research,"With the increasing popularity of computational approaches to conduct social science research, building a scalable and efficient computing platform has become a topic of interest for academia to empower research labs and institutes to analyze large-scale data. While social science researchers have been very excited about the advancement of emerging technologies in big data, deep learning, computer vision, network analysis, etc., they are also constrained by the available computing resources to analyze data. This paper describes a scalable solution to deploy JupyterHub for computational social science research on the cloud. We use a reference architecture on AWS to walk through the design principles and details. Our architecture has helped facilitate several collaborations between Facebook and academia the case study (Facebook Open Research and Transparency platform) shows that our architecture, using technologies like containerization and serverless computing, can support thousands of users to analyze web-scale datasets. © 2021 Owner/Author."
Gillis: Serving large neural networks in serverless functions with automatic model partitioning,"The increased use of deep neural networks has stimulated the growing demand for cloud-based model serving platforms. Serverless computing offers a simplified solution: users deploy models as serverless functions and let the platform handle provisioning and scaling. However, serverless functions have constrained resources in CPU and memory, making them inefficient or infeasible to serve large neural networks-which have become increasingly popular. In this paper, we present Gillis, a serverless-based model serving system that automatically partitions a large model across multiple serverless functions for faster inference and reduced memory footprint per function. Gillis employs two novel model partitioning algorithms that respectively achieve latency-optimal serving and cost-optimal serving with SLO compliance. We have implemented Gillis on three serverless platforms-AWS Lambda, Google Cloud Functions, and KNIX-with MXNet as the serving backend. Experimental evaluations against popular models show that Gillis supports serving very large neural networks, reduces the inference latency substantially, and meets various SLOs with a low serving cost. © 2021 IEEE."
Serverless distributed learning for smart grid analytics,"The digitization, informatization, and intelligentization of physical systems require strong support from big data analysis. However, due to restrictions on data security and privacy and concerns about the cost of big data collection, transmission, and storage, it is difficult to do data aggregation in real-world power systems, which directly retards the effective implementation of smart grid analytics. Federated learning, an advanced distributed learning method proposed by Google, seems a promising solution to the above issues. Nevertheless, it relies on a server node to complete model aggregation and the framework is limited to scenarios where data are independent and identically distributed. Thus, we here propose a serverless distributed learning platform based on blockchain to solve the above two issues. In the proposed platform, the task of machine learning is performed according to smart contracts, and encrypted models are aggregated via a mechanism of knowledge distillation. Through this proposed method, a server node is no longer required and the learning ability is no longer limited to independent and identically distributed scenarios. Experiments on a public electrical grid dataset will verify the effectiveness of the proposed approach. © 2021 Chinese Physical Society and IOP Publishing Ltd."
DEBS 2021 - Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems,"The proceedings contain 26 papers. The topics discussed include: a distributed database system for event-based microservices; distributed transactions on serverless stateful functions; towards event-driven decentralized marketplaces on the blockchain; an experimental framework for improving the performance of BFT consensus for future permissioned blockchains; fast recovery of correlated failures in distributed stream processing engines; an event driven framework for smart contract execution; box queries over multi-dimensional streams; real-time big data stream analytics and complex event detection: modular visual framework, data science platform, and industry applications; S2CE: a hybrid cloud and edge orchestrator for mining exascale distributed streams; descriptor based consensus for blockchain transactions; and the synergy of complex event processing and tiny machine learning in industrial IoT."
Efficient GPU Sharing for Serverless Workflows,"Serverless computing has emerged as a new cloud computing paradigm, where an application consists of individual functions that can be separately managed and executed. However, the function development environment of all serverless computing frameworks at present is CPU-based. In this paper, we propose to extend the open-sourced KNIX high-performance serverless framework so that it can execute functions on shared GPU cluster resources. We have evaluated the performance impacts on the extended KNIX system by measuring overheads and penalties incurred using different deep learning frameworks. © 2020 ACM."
SLA-Aware Workload Scheduling Using Hybrid Cloud Services,"Cloud services have an auto-scaling feature for load balancing to meet the performance requirements of an application. Existing auto-scaling techniques are based on upscaling and downscaling cloud resources to distribute the dynamically varying workloads. However, bursty workloads pose many challenges for auto-scaling and sometimes result in Service Level Agreement (SLA) violations. Furthermore, over-provisioning or under-provisioning cloud resources to address dynamically evolving workloads results in performance degradation and cost escalation. In this work, we present a workload characterization based approach for scheduling the bursty workload on a highly scalable serverless architecture in conjunction with a machine learning (ML) platform. We present the use of Amazon Web Services (AWS) ML platform SageMaker and serverless computing platform Lambda for load balancing the inference workload to avoid SLA violations. We evaluate our approach using a recommender system that is based on a deep learning model for inference. © 2020 ACM."
Towards situational awareness with multimodal streaming data fusion: Serverless computing approach,"The availability of large quantities of data has given an impulse for methods and techniques to extract unseen useful knowledge and process it in a fast and scalable manner. In order to extract the most complete possible knowledge from the continuous data stream, it is necessary to use the heterogeneous data sources and process information from multiple modalities. The systems that utilize multimodal data must take advantage of the up-To-date approaches for data storage, usage, cleaning and storage. Neural networks and machine learning approaches are widely used for data-heavy software where pattern extractions and predictions need to be conducted while serverless computing frameworks are being increasingly used for machine learning solutions to optimize cost and speed of such systems. This work presents a framework for processing data from multimodal sources where the task of feature and pattern extraction is performed on a serverless computing platform. The use cases for public safety solutions to increase situational awareness are described and compared with other implementation approaches. © 2021 Owner/Author."
Pilot-Edge: Distributed Resource Management along the Edge-to-Cloud Continuum,"Many science and industry IoT applications necessitate data processing across the edge-to-cloud continuum to meet performance, security, cost, and privacy requirements. However, diverse abstractions and infrastructures for managing resources and tasks across the edge-to-cloud scenario are required. We propose Pilot-Edge as a common abstraction for resource management across the edge-to-cloud continuum. Pilot-Edge is based on the pilot abstraction, which decouples resource and workload management, and provides a Function-as-a-Service (FaaS) interface for application-level tasks. The abstraction allows applications to encapsulate common functions in high-level tasks that can then be configured and deployed across the continuum. We characterize Pilot-Edge on geographically distributed infrastructures using machine learning workloads (e. g., k-means and auto-encoders). Our experiments demonstrate how Pilot-Edge manages distributed resources and allows applications to evaluate task placement based on multiple factors (e. g., model complexities, throughput, and latency). © 2021 IEEE."
Production of global daily seamless data cubes and quantification of global land cover change from 1985 to 2020 - iMap World 1.0,"Longer time high-resolution, high-frequency, consistent, and more detailed land cover data are urgently needed in order to achieve sustainable development goals on food security, high-quality habitat construction, biodiversity conservation and planetary health, and for the understanding, simulation and management of the Earth system. However, due to technological constraints, it is difficult to provide simultaneously high spatial resolution, high temporal frequency, and high quality observation data. Existing mapping solutions are limited by traditional remotely sensed data, that have shorter observation periods, poor spatio-temporal consistency and comparability. Therefore, a new mapping paradigm is needed. This paper develops a framework for intelligent mapping (iMap) of land cover based on state-of-the-art technologies such as cloud computing, artificial intelligence, virtual constellations, and spatio-temporal reconstruction and fusion. Under this framework, we built an automated, serverless, end-to-end data production chain and parallel mapping system based on Amazon Web Services (AWS) and produced the first 30 m global daily seamless data cubes (SDC), and annual to seasonal land cover maps for 1985–2020. The SDC was produced through a multi-source spatio-temporal data reconstruction and fusion workflow based on Landsat, MODIS, and AVHRR virtual constellations. Independent validation results show that the relative mean error of the SDC is less than 2.14%. As analysis ready data (ARD), it can lay a foundation for high-precision quantitative remote sensing information extraction. From this SDC, we produced 36-year long, 30 m resolution global land cover map data set by combining strategies of sample migration, machine learning, and spatio-temporal adjustment. The average overall accuracy of our annual land cover maps over multiple periods of time is 80% for level 1 classification and over 73% for level 2 classification (29 and 33 classes). Based on an objective validation sample consisting of FLUXNET sites, our map accuracy is 10% higher than that of existing global land cover datasets including Globeland30. Our results show that the average global land cover change rate is 0.36%/yr. Global forest decreased by 1.47 million km2 from 38.44 million km2, cropland increased by 0.84 million km2 from 12.49 million km2 and impervious surface increased by 0.48 million km2 from 0.57 million km2 during 1985– 2020. © 2021 The Author(s)"
A Deep Intrusion Detection System in Lambda Architecture Based on Edge Cloud Computing for IoT,"IoT devices enable a massive amount of data to be aggregated and analyzed for anomaly detection. The nature of heterogeneous devices introduces the challenge of collecting and handling these massive datasets to perform data analyses to discover cyber attacks in near real-time. However, the traditional IDS cannot deal with such a problem due to scalability limitations and insufficient storage and processing capabilities. Moreover, issues such as network bandwidth, real-time support, and security limit the power of cloud server-based IDSs. This paper presents an edge-cloud deep IDS model in Lambda architecture for IoT security to address these challenges. Our system decreases the training phase's time compared to traditional machine learning algorithms and increases the accuracy of true positive detected attacks. Furthermore, neural network layers lead deep learning to achieve better performance and flexibility compared to conventional machine learning. Our solution enables the detection of suspicious activities in real-time and allows to classify them by analyzing historical data in a batch process. © 2021 IEEE."
Automatic Hyperparameter Optimization for Arbitrary Neural Networks in Serverless AWS Cloud,"Deep Neural Networks are the most efficient method to solve many challenging problems. The importance of the subject can be demonstrated by the fact that the 2019 Turing Award was given to the godfathers of AI (and Neural Networks) Yoshua Bengio, Geoffrey Hinton, and Yann LeCun. In spite of the numerous advancements in the field, most of the models are being tuned manually. Accurate models became especially important during the novel coronavirus pandemic.Many day-to-day decisions depend on the model predictions affecting billions of people. We implemented a flexible automatic real-time hyperparameter tuning approach for arbitrary DNN models written in Python and Keras without manual steps. All of the existing tuning libraries require manual steps (like hyperopt, Scikit-Optimize or SageMaker). We provide an innovative methodology to automate hyper-parameter tuning for an arbitrary Neural Network model source code, utilizing Serverless Cloud and implementing revolutionary microservices, security, interoperability and orchestration. Our methodology can be used in numerous applications, including Information and Communication Systems. © 2021 IEEE."
OpenDC 2.0: Convenient modeling and simulation of emerging technologies in cloud datacenters,"Cloud datacenters are important for the digital society, serving stakeholders across industry, government, and academia. Simulation is a critical part of exploring datacenter technologies, enabling scalable experimentation with millions of jobs and hundreds of thousands of machines, and what-if analysis in a matter of minutes to hours. Although the community has already developed powerful simulators, emerging technologies and applications in modern datacenters require new approaches. Addressing this requirement, in this work we propose OpenDC, a new platform for datacenter simulation. OpenDC includes novel models for emerging cloud-datacenter technologies and applications, such as serverless computing with FaaS deployment and TensorFlow-based machine learning. Our design also focuses on convenience, with a web-based interface for interactive experimentation, support for experiment automation, a library of prefabs for constructing and sharing datacenter designs, and support for diverse input formats and output metrics. We implement, validate, and open-source OpenDC 2.0, a significant redesign and release after a multi-year research and development process. We demonstrate the benefits of OpenDC for the field through a set of representative use-cases: serverless, machine learning, procurement of HPC-as-a-Service infrastructure, educational practices, and reproducibility studies. Overall, OpenDC helps understand how datacenters work, design datacenter infrastructure, and train the next generation of experts. © 2021 IEEE."
High performance serverless architecture for deep learning workflows,"Serverless architecture is a rapidly growing paradigm for deploying deep learning applications performing ephemeral computing and serving bursty workloads. Serverless architecture promises automatic scaling and cost efficiency for inferencing deep learning models while minimizing the operational logic. However, serverless computing is stateless with constraints on local resources. Hence, deploying complex deep learning applications containing large size models, frameworks, and libraries is a challenge.In this work, we discuss a methodology and architecture for migrating deep vision algorithms and model based applications to a serverless computing platform. We have tested our methodology using AWS infrastructure (AWS Lambda, Provisioned Concurrency, VPC endpoint, S3 and EFS) to mitigate the challenges in deploying composition of APIs containing large deep learning models and frameworks. We evaluate the performance and cost of our architecture for a real-life enterprise application used for document processing. © 2021 IEEE."
OFC: An opportunistic caching system for FaaS platforms,"Cloud applications based on the ""Functions as a Service""(FaaS) paradigm have become very popular. Yet, due to their stateless nature, they must frequently interact with an external data store, which limits their performance. To mitigate this issue, we introduce OFC, a transparent, vertically and horizontally elastic in-memory caching system for FaaS platforms, distributed over the worker nodes. OFC provides these benefits cost-effectively by exploiting two common sources of resource waste: (i) most cloud tenants overprovision the memory resources reserved for their functions because their footprint is non-trivially input-dependent and (ii) FaaS providers keep function sandboxes alive for several minutes to avoid cold starts. Using machine learning models adjusted for typical function input data categories (e.g., multimedia formats), OFC estimates the actual memory resources required by each function invocation and hoards the remaining capacity to feed the cache. We build our OFC prototype based on enhancements to the OpenWhisk FaaS platform, the Swift persistent object store, and the RAM-Cloud in-memory store. Using a diverse set of workloads, we show that OFC improves by up to 82 % and 60 % respectively the execution time of single-stage and pipelined functions. © 2021 ACM."
Distributed double machine learning with a serverless architecture,"This paper explores serverless cloud computing for double machine learning. Being based on repeated cross-fitting, double machine learning is particularly well suited to exploit the high level of parallelism achievable with serverless computing. It allows to get fast on-demand estimations without additional cloud maintenance effort. We provide a prototype Python implementation DoubleML-Serverless for the estimation of double machine learning models with the serverless computing platform AWS Lambda and demonstrate its utility with a case study analyzing estimation times and costs. © 2021 Copyright held by the owner/author(s)."
ICPE 2021 - Companion of the ACM/SPEC International Conference on Performance Engineering,"The proceedings contain 36 papers. The topics discussed include: towards independent run-time cloud monitoring; distributed double machine learning with a serverless architecture; cloud performance variability prediction; 10 years later: cloud computing is closing the performance gap; performance and cost comparison of cloud services for deep learning workload; GradeML: towards holistic performance analysis for machine learning workflows; an empirical evaluation of the performance of video conferencing systems; enabling containerized, parametric and distributed database deployment and benchmarking as a service; how to measure scalability of distributed stream processing engines?; and performance interference on key-value stores in multi-tenant environments: when block size and write requests matter."
Performance and cost comparison of cloud services for deep learning workload,"Many organizations are migrating their on-premise artificial intelligence workloads to the cloud due to availability of cost-effective and highly scalable infrastructure, software and platform services. To ease the process of migration, many cloud vendors provide services, frameworks and tools that can be used for deployment of applications on cloud infrastructure. Finding the most appropriate service and infrastructure for a given application that results in a desired performance at minimal cost, is a challenge. In this work, we present a methodology to migrate a deep learning model based recommender system to ML platform and serverless architecture. Furthermore, we show our experimental evaluation of AWS ML platform called SageMaker and the serverless platform service known as Lambda. In our study, we also discuss performance and cost trade-off while using cloud infrastructure. © 2021 Association for Computing Machinery."
An Improved Task Allocation Scheme in Serverless Computing Using Gray Wolf Optimization (GWO) Based Reinforcement Learning (RIL) Approach,"Serverless computing offers a wide variety of event-driven integrations and cloud services, easy development and implementation frameworks, and complex balancing and control of costs. With these benefits into consideration, the growing implementation of serverless systems means that the performance of the serverless system is measured and new techniques created to maximize the potential of the software. The serverless or system runtime features have shown major performance and cost advantages for event-driven cloud applications. While serverless runtimes are limited to applications requiring lightweight data and storage, such as the prediction and inference of machine learning, these applications have been improved beyond other cloud runtimes. In this paper, we propose a machine learning model to parallelize the jobs allocated to the event queue and the dispatcher of the serverless framework. We hence use Gray Wolf Optimization (GWO) model to improve the process of task allocation. Further, to optimize GWO, we use the Reinforcement Learning (RIL) approach that simultaneously optimizes the parameters of GWO and improves the task allocation. The simulation studies show that the proposed GWO-RIL offers reduced runtimes and it adapts with varying load conditions. © 2020, Springer Science+Business Media, LLC, part of Springer Nature."
"Proceedings of the 36th Annual ACM Symposium on Applied Computing, SAC 2021",The proceedings contain 252 papers. The topics discussed include: efficient DNA sequence partitioning using probabilistic subsets and hypergraphs; natural vs balanced distribution in deep learning on whole slide images for cancer detection; protein secondary structure prediction based on fusion of machine learning classifiers; stargate: remote data access between hadoop clusters; reducing cold starts during elastic scaling of containers in kubernetes; an energy saving approach: understanding microservices as multidimensional entities in P2P networks; workload classification in multi-VM cloud environment using deep neural network model; cost minimization for deploying serverless functions; a bargaining game based energy-aware load balancing in cloud data centers; low-cost automatic fish measuring estimation; topple-free foot strategy applied to real-time motion capture data using kinect sensor; and EMIDAS: explainable social interaction-based pedestrian intention detection across street.
Machine learning and price-based load scheduling for an optimal IoT control in the smart and frugal home,"We pose and study a scheduling problem for an electric load to develop an Internet of Things (IoT) control system for power appliances, which takes advantage of real-time dynamic energy pricing. Using historical pricing data from a large U.S. power supplier, we study and compare several dynamic scheduling policies, which can be implemented in a smart home to activate a major appliance (dishwasher, washing machine, clothes dryer) at an optimal time of the day, to minimize electricity costs. We formulate our scheduling task as a supervised machine learning classification problem which activates the load during one of two preferred time bins. The features used in the machine learning problem are hourly market, spot and day-ahead prices along with delayed label of the prior day. We find that boosting tree-based algorithms outperform any other classification approach with measurable reduction of energy costs over certain types of naive and static policies. We observe that the delayed label has most predictive power across features, followed, on average, by spot, hourly market, and day-ahead energy prices. We further discuss implementation issues using a micro controller system coupled with cloud-based serverless computing and dynamic data storage. Our test system includes an interactive voice interface via an intelligent personal assistant. © 2020 The Authors"
Leveraging the serverless paradigm for realizing machine learning pipelines across the edge-cloud continuum,"The exceedingly exponential-growing data rate highlighted numerous requirements and several approaches have been released to maximize the added-value of cloud and edge resources. Whereas data scientists utilize algorithmic models in order to transform datasets and extract actionable knowledge, a key challenge is oriented towards abstracting the underline layers: the ones enabling the management of infrastructure resources and the ones responsible to provide frameworks and components as services. In this sense, the serverless approach features as the novel paradigm of new cloud-related technology, enabling the agile implementation of applications and services. The concept of Function as a Service (FaaS) is introduced as a revolutionary model that offers the means to exploit serverless offerings. Developers have the potential to design their applications with the necessary scalability in the form of nanoservices without addressing themselves the way the infrastructure resources should be deployed and managed. By abstracting away the underlying hardware allocations, the data scientist concentrates on the business logic and critical problems of Machine Learning (ML) algorithms. This paper introduces an approach to realize the provision of ML Functions as a Service (i.e., ML-FaaS), by exploiting the Apache OpenWhisk event-driven, distributed serverless platform. The presented approach tackles also composite services that consist of single ones i.e., workflows of ML tasks including processes such as aggregation, cleaning, feature extraction, and analytics; thus, reflecting the complete data path. We also illustrate the operation of the approach mentioned above and assess its performance and effectiveness exploiting a holistic, end-toend anti-fraud detection machine learning pipeline. © 2021 IEEE."
Architectural vision of cloud computing in the indian government,"The GI (Govt. of India) cloud started in 2014 is built on the state of art technologies and rich architecture with the nationwide network infrastructure and Data Centres located across the country on National and State data centres. This paper investigates, study and analyze the cloud architecture of Govt. of India and suggests modifications that need to be adapted for sustainable development as per the global changing scenario and fulfill the future needs with improved service delivery, increased throughput, and increased efficiency to provide secured cloud services and to minimize the gap between the cloud service providers and end-users. The cloud services are designed for centralized storage and processing. The cloud data centers are generally located thousands of miles away from the end-users where the data is actually generated. The physical distance between the cloud infrastructure and the data source at edge level end-users produces latency for the real-time processing of the huge amount of data generated at the source level. In recent years the automation scenario is changing globally with various emerging technologies such as the Internet of Things (IoT), Wireless Fidelity 6 (Wi-Fi 6), Fifth Generation Mobile Network connectivity (5G), Artificial Intelligence (AI), and Machine Learning, etc. Emerging technologies like IoT, Wi-Fi 6, 5G gives large scope for boundary level computing and generates a very huge amount of data at the data source level produced by the end-users. These technologies require agile real-time processing and analysis of the data at the source level. Edge computing and Fog computing are the distributed architectures that work together, for reduced latency and speedy real-time processing where the data is actually generated by the end-user. According to the new implementation demands, various emerging cloud technologies such as Mobile Cloud Apps, Containers, Serverless, Microservices, Development and Information Technology Operations (DevOps), BlockChain, Fog computing, Edge Computing, and Software-Defined Infrastructure (SDI), etc are proposed for implementation © 2021 IEEE."
21st century daily seamless data cube reconstruction and seasonal to annual land cover and land use dynamics mapping-iMap (China) 1.0 [21世纪逐日无缝数据立方体构建方法及逐年逐季节土地覆盖和土地利用动态制图-中国智慧遥感制图iMap (China) 1.0],"Sustainable development goals such as food security, high-quality habitat construction, biodiversity conservation, planetary health, and the understanding, modeling, and management of the Earth system urgently require multi-scale, long time series, high-accuracy, and consistent remote sensing observation datasets and mapping products with flexible classification systems to meet user needs. However, due to technical and cost constraints, it is difficult for conventional remote sensing satellites to provide observations with high spatial resolution, high temporal frequency, and high quality at the same time. The existing mapping and inversion schemes are mostly for a single sensor, making it difficult to fully exploit and jointly utilize the information potential of multi-source heterogeneous remote sensing big data, resulting in limited observation periods and resolutions, low spatial and temporal consistency and comparability. Therefore, new technical paradigms are urgently needed in the field of remote sensing. In this paper, based on advanced technologies, including cloud computing, artificial intelligence, virtual constellation, spatio-temporal fusion reconstruction, an intelligent mapping framework is proposed for remote sensing big data. The framework is user-driven and problem-driven, which can significantly improve the current situation that remote sensing data products can hardly meet users' diversified and high-precision surface monitoring needs in agriculture and forestry management, national monitoring, ecological environment protection, disaster prevention and mitigation, urban planning, etc. Under this framework's guidance, we built an online real-time, automated, serverless, end-to-end remote sensing big data production chain and parallel mapping system based on Amazon Web Services (AWS) high-performance, elastic, and scalable distributed computing resources. We produced the first set of 21st century daily Seamless Data Cube (SDC) and seasonal to annual land cover and land use mapping products of China. Integrating Landsat and MODIS satellite as a virtual constellation, through multi-source spatio-temporal data fusion and reconstruction technology, the daily SDC, cloud-free, high-precision reflectance product, is developed. As Analysis Ready Data (ARD), it lays the foundation for high-precision quantitative remote sensing inversion and mapping. Based on SDC, we developed the seasonal to annual mapping product with multiple multi-level land cover and land use classification systems, whose mean annual accuracy exceeds 80%. The main mapping pipeline includes migrating the all-season sample set based on stable classification theory with limited samples, optimizing and ensembling multiple classifiers by Automatic Machine Learning (AutoML) strategies, and using change detection and post-processing techniques to achieve consistency. The two sets of products demonstrate the feasibility and effectiveness of the intelligent remote sensing mapping framework proposed in this paper. We will continue to improve and develop the framework with an open and flexible concept to provide new ideas to promote remote sensing development in China. © 2021, Science Press. All right reserved."
TableNN: Deep Learning Framework for Learning Domain Specific Tabular Data,"Enterprises often have a large number of databases and other sources of tabular data with columns full of domain-specific jargon (e.g. alpha-numeric codings, undeclared abbreviations, etc) which usually require domain experts to decode. Due to the jargon-specific content of the tables, no pre-trained language model such as Wiki2Vec [21] can be applied readily to encode the cell semantics due to absence of unique jorgan words or alpha-numeric codes in the model vocabulary. We propose a deep learning based framework that is ideally suited for serverless computing environment, and that 1) uses a new tokenization method, called Cell-Masking, 2) encodes the semantics of the cells into contextual embedding that exploits the locality features in tabular data, called Cell2Vec, and 3) an attention-based neural network, called TableNN, that provides a supervised learning solution to classify cell entries into predefined column classes. We apply the proposed method on three publicly available datasets of varying data sizes, from different industries. Cell-Masking provides an order of magnitude lower loss value and quickest convergence for cell embedding generation. In Cell2Vec, we demonstrate that the inclusion of row and column context improves the quality of embeddings by better loss curve convergence and improvement in accuracy by 5.4% on the BTS dataset [3]. © 2021 IEEE."
FedLess: Secure and Scalable Federated Learning Using Serverless Computing,"The traditional cloud-centric approach for Deep Learning (DL) requires training data to be collected and processed at a central server which is often challenging in privacy-sensitive domains like healthcare. Towards this, a new learning paradigm called Federated Learning (FL) has been proposed that brings the potential of DL to these domains while addressing privacy and data ownership issues. FL enables clients to learn a shared ML model while keeping the data local. However, conventional FL systems face challenges such as scalability, complex infrastructure management, and wasted compute and incurred costs due to idle clients. These challenges of FL systems closely align with the core problems that serverless computing and Function-as-a-Service (FaaS) platforms aim to solve. These include rapid scalability, no infrastructure management, automatic scaling to zero for idle clients, and a pay-per-use billing model. To this end, we present a novel system and framework for serverless FL, called FedLess. Our system supports multiple commercial and self-hosted FaaS providers and can be deployed in the cloud, on-premise in institutional data centers, and on edge devices. To the best of our knowledge, we are the first to enable FL across a large fabric of heterogeneous FaaS providers while providing important features like security and Differential Privacy. We demonstrate with comprehensive experiments that the successful training of DNNs for different tasks across up to 200 client functions and more is easily possible using our system. Furthermore, we demonstrate the practical viability of our methodology by comparing it against a traditional FL system and show that it can be cheaper and more resource-efficient. © 2021 IEEE."
FedSmarteum: Secure Federated Matrix Factorization Using Smart Contracts for Multi-Cloud Supply Chain,"With increased awareness comes unprecedented expectations. We live in a digital, cloud era wherein the underlying information architectures are expected to be elastic, secure, resilient, and handle petabyte scaling. The expectation of epic proportions from the next generation of the data frameworks is to not only do all of the above but also build it on a foundation of trust and explainability across multi-organization business networks. From cloud providers to automobile industries or even vaccine manufacturers, components are often sourced by a complex, not full digitized thread of disjoint suppliers. Building Machine Learning and AI-based order fulfillment and predictive models, remediating issues, is a challenge for multi-organization supply chain automation. We posit that Federated Learning in conjunction with blockchain and smart contracts are technologies primed to tackle data privacy and centralization challenges. In this paper, motivated by challenges in the industry, we propose a decentralized distributed system in conjunction with a recommendation system model (Matrix Factorization) that is trained using Federated Learning on an Ethereum blockchain network. We leverage smart contracts that allow decentralized serverless aggregation to update local-ized items vectors. Furthermore, we utilize Homomorphic Encryption (HE) to allow sharing the encrypted gradients over the network while maintaining their privacy. Based on our results, we argue that training a model over a serverless Blockchain network using smart contracts will provide the same accuracy as in a centralized model while maintaining our serverless model privacy and reducing the overhead communication to a central server. Finally, we assert such a system that provides transparency, audit-ready and deep insights into supply chain operations for enterprise cloud customers resulting in cost savings and higher Quality of Service (QoS). © 2021 IEEE."
Deployment and Management of Time Series Forecasts in Ocean Industry,"Machine learning has not achieved the same degree of success in environmental applications as in other industries. Challenges around data sparsity, quality, and consistency have limited the impact of deep neural network approaches and restricted the focus to research applications. An alternative approach - that is more amenable to the characteristics of data coming from disparate IoT devices deployed at different times and locations in the ocean - is to develop many lightweight models that can be readily scaled up or down based on the number of devices available at any time. This paper presents a serverless framework that naturally marries a single IoT sensor device with a forecasting model. Aspects related to data ingestion, data processing, model training and deployment are described. The framework is applied to a fish farm site in Atlantic Canada. © 2021 IEEE."
Cross-Platform Performance Evaluation of Stateful Serverless Workflows,"Serverless computing, with its inherent event-driven design along with instantaneous scalability due to cloud-provider managed infrastructure, is starting to become a de-facto model for deploying latency critical user-interactive services. However, as much as they are suitable for event-driven services, their stateless nature is a major impediment for deploying long-running stateful applications. While commercial cloud providers offer a variety of solutions that club serverless functions along with intermediate storage to maintain application state, they are still far from optimized for deploying stateful applications at scale. More specifically, factors such as storage latency and scalability, network bandwidth, and deployment costs play a crucial role in determining whether current serverless applications are suitable for stateful workloads. In this paper, we evaluate the two widely-used stateful server-less offerings, Azure Durable functions and AWS Step functions, to quantify their effectiveness for implementing complex stateful workflows. We conduct a detailed measurement-driven characterization study with two real-world use cases, machine learning pipelines (inference and training) and video analytics, in order to characterize the different performance latency and cost tradeoffs. We observe from our experiments that AWS is suitable for workloads with higher degree of parallelism, while Azure durable entities offer a simplified framework that enables quicker application development. Overall, AWS is 89% more expensive than Azure for machine learning training application while Azure is 2× faster than AWS for the machine learning inference application. Our results indicate that Azure durable is extremely inefficient in implementing parallel processing. Furthermore, we summarize the key findings from our characterization, which we believe to be insightful for any cloud tenant who has the problem of choosing an appropriate cloud vendor and offering, when deploving stateful workloads on serverless platforms, © 2021 IEEE."
FaaSRank: Learning to Schedule Functions in Serverless Platforms,"Current serverless Function-as-a-Service (FaaS) platforms generally use simple, classic scheduling algorithms for distributing function invocations while ignoring FaaS characteristics such as rapid changes in resource utilization and the freeze-thaw life cycle. In this paper, we present FaaSRank, a function scheduler for serverless FaaS platforms based on information monitored from servers and functions. FaaSRank automatically learns scheduling policies through experience using reinforcement learning (RL) and neural networks supported by our novel Score-Rank-Select architecture. We implemented FaaSRank in Apache OpenWhisk, an open source FaaS platform, and evaluated performance against other baseline schedulers including OpenWhisk's default scheduler on two 13-node OpenWhisk clusters. For training and evaluation, we adapted real-world serverless workload traces provided by Microsoft Azure. For the duration of test workloads, FaaSRank sustained on average a lower number of inflight invocations 59.62 % and 70.43 % as measured on two clusters respectively. We also demonstrate the generalizability of FaaSRank for any workload. When trained using a composite of 50 episodes each for 10 distinct random workloads, FaaSRank reduced average function completion time by 23.05% compared to OpenWhisk's default scheduler. © 2021 IEEE."
"2021 ITU Kaleidoscope: Connecting Physical and Virtual Worlds, ITU K 2021","The proceedings contain 25 papers. The topics discussed include: deviceless: a serverless approach for the Internet of things; exploring the essence of communication to reach the heart; the adoption gap: ethics, citizenship, institutional factors, and standards for smart cities; strengthen the security of cyberspace with device-independent quantum randomness; optimal pilot sequence design for machine learning based channel estimation in FDD massive MIMO systems; optimizing packet transmission for ledger-based points transfer system in LPWAN: solutions, evaluation and standardization; enhancing the system model for home interior design using augmented reality; and future industrial networks: requirements, challenges, research and standardization needs."
Introduction to Digital Libraries,"This tutorial is a thorough and deep introduction to the Digital Libraries (DL) field, providing a firm foundation: covering key concepts and terminology, as well as services, systems, technologies, methods, standards, projects, issues, and practices. It introduces and builds upon a firm theoretical foundation (starting with the '5S' set of intuitive aspects: Streams, Structures, Spaces, Scenarios, Societies), giving careful definitions and explanations of all the key parts of a 'minimal digital library', and expanding from that basis to cover key DL issues. Illustrations come from a set of case studies, including from multiple current projects, including with the application of natural language processing and machine learning to webpages, tweets, and long documents. Attendees will be exposed to four Morgan and Claypool books that elaborate on 5S. Further, new material will be added on building digital libraries using container and cloud services, on developing a digital library for electronic theses and dissertations, and methods to integrate UX and DL design approaches. © 2021 IEEE."
WidePipe: High-Throughput Deep Learning Inference System on a Cluster of Neural Processing Units,"The wide application of machine learning technology promotes the generation of ML-as-a-Service(MLaaS), which is a serverless computing paradigm for rapidly deploying a trained model as a serving. However, it is a challenge to design an inference system that is capable of coping with large traffic for low latency and heterogeneous neural networks. It is difficult to adaptively configure multilevel parallelism in existing cloud inference systems for machine learning servings, particularly if the cluster has accelerators, such as GPUs, NPUs, FPGAs, etc. These issues lead to poor resource utilization and limit the system throughput. In this paper, we propose and implement a high-throughput inference system called WidePipe, which WidePipe leverages reinforcement learning to co-adapt resource allocation and batch size of request according to device status. We evaluated the performance of WidePipe for a large cluster with 1000 neural processing units in 250 nodes. Our experimental results show that WidePipe has a 2.11× higher throughput than current inference systems when deploying heterogeneous machine learning servings, meeting the service-level objectives for the response time. © 2021 IEEE."
Quantifying and Improving Performance of Distributed Deep Learning with Cloud Storage,"Cloud computing provides a powerful yet low-cost environment for distributed deep learning workloads. However, training complex deep learning models often requires accessing large amounts of data, which can easily exceed the capacity of local disks. Prior research often overlooks this training data problem by implicitly assuming that data is available locally or via low latency network-based data storage. Such implicit assumptions often do not hold in a cloud-based training environment, where deep learning practitioners create and tear down dedicated GPU clusters on demand, or do not have the luxury of local storage, such as in serverless workloads. In this work, we investigate the performance of distributed training that leverages training data residing entirely inside cloud storage buckets. These buckets promise low storage costs, but come with inherent bandwidth limitations that make them seem unsuitable for an efficient training solution. To account for these bandwidth limitations, we propose the use of two classical techniques, namely caching and pre-fetching, to mitigate the training performance degradation. We implement a prototype, DELI, based on the popular deep learning framework PyTorch by building on its data loading abstractions. We then evaluate the training performance of two deep learning workloads using Google Cloud's NVIDIA K80 GPU servers and show that we can reduce the time that the training loop is waiting for data by 85.6%-93.5% compared to loading directly from a storage bucket-thus achieving comparable performance to loading data directly from disk-while only storing a fraction of the data locally at a time. In addition, DELI has the potential of lowering the cost of running a training workload, especially on models with long per-epoch training times. © 2021 IEEE."
Research on Parallel Support Vector Machine Based on Spark Big Data Platform,"With the development of cloud computing and distributed cluster technology, the concept of big data has been expanded and extended in terms of capacity and value, and machine learning technology has also received unprecedented attention in recent years. Traditional machine learning algorithms cannot solve the problem of effective parallelization, so a parallelization support vector machine based on Spark big data platform is proposed. Firstly, the big data platform is designed with Lambda architecture, which is divided into three layers: Batch Layer, Serving Layer, and Speed Layer. Secondly, in order to improve the training efficiency of support vector machines on large-scale data, when merging two support vector machines, the ""special points""other than support vectors are considered, that is, the points where the nonsupport vectors in one subset violate the training results of the other subset, and a cross-validation merging algorithm is proposed. Then, a parallelized support vector machine based on cross-validation is proposed, and the parallelization process of the support vector machine is realized on the Spark platform. Finally, experiments on different datasets verify the effectiveness and stability of the proposed method. Experimental results show that the proposed parallelized support vector machine has outstanding performance in speed-up ratio, training time, and prediction accuracy. © 2021 Yao Huimin."
Reputation-aware Hedonic Coalition Formation for Efficient Serverless Hierarchical Federated Learning,"Amid growing concerns on data privacy, Federated Learning (FL) has emerged as a promising privacy preserving distributed machine learning paradigm. Given that the FL network is expected to be implemented at scale, several studies have proposed system architectures towards improving the network scalability and efficiency. Specifically, the Hierarchical FL (HFL) network utilizes cluster heads, e.g., base stations, for the intermediate aggregation and relay of model parameters. Serverless FL is also proposed recently, in which the data owners, i.e., workers, exchange the local model parameters among a neighborhood of workers. This decentralized approach reduces the risk of a single point of failure but inevitably incurs significant communication overheads. To achieve the best of both worlds, we propose the Serverless Hierarchical Federated Learning (SHFL) framework in this paper. The SHFL framework adopts a two-layer system architecture. In the lower layer, the FL workers are grouped into clusters under cluster heads. In the upper layer, the cluster heads exchange the intermediate parameters with their one-hop neighbors without the aid of a central server. To improve the sustainable efficiency of the FL system while taking into account the incentive design for workers marginal contributions in the system, we propose the reputation-aware hedonic coalition formation game in this paper. Specifically, the workers are rewarded for their marginal contribution to the cluster, whereas the reputation opinions of each cluster head is updated in a decentralized manner, thereby deterring malicious behaviors by the cluster head. This improves the performance of the network since cluster heads with higher reputation scores are more reliable in relaying the intermediate model parameters. The simulation results show that our proposed hedonic coalition formation algorithm converges to a Nash-stable partition and improves the network efficiency. IEEE"
Toward Sustainable Serverless Computing,"Although serverless computing generally involves executing short-lived functions, the increasing migration to this computing paradigm requires careful consideration of energy and power requirements. serverless computing is also viewed as an economically-driven computational approach, often influenced by the cost of computation, as users are charged for per-subsecond use of computational resources rather than the coarse-grained charging that is common with virtual machines and containers. To ensure that the startup times of serverless functions do not discourage their use, resource providers need to keep these functions hot, often by passing in synthetic data. We describe the real power consumption characteristics of serverless, based on execution traces reported in the literature, and describe potential strategies (some adopted from existing VM and container-based approaches) that can be used to reduce the energy overheads of serverless execution. Our analysis is, purposefully, biased toward the use of machine learning workloads because: (1) workloads are increasingly being used widely across different applications; (2) functions that implement machine learning algorithms can range in complexity from long-running (deep learning) versus short-running (inference only), enabling us to consider serverless across a variety of possible execution behaviors. The general findings are easily translatable to other domains. © 1997-2012 IEEE."
A serverless gateway for event-driven machine learning inference in multiple clouds,"Serverless computing and, in particular, the functions as a service model has become a convincing paradigm for the development and implementation of highly scalable applications in the cloud. This is due to the transparent management of three key functionalities: triggering of functions due to events, automatic provisioning and scalability of resources, and fine-grained pay-per-use. This article presents a serverless web-based scientific gateway to execute the inference phase of previously trained machine learning and artificial intelligence models. The execution of the models is performed both in Amazon Web Services and in on-premises clouds with the OSCAR framework for serverless scientific computing. In both cases, the computing infrastructure grows elastically according to the demand adopting scale-to-zero approaches to minimize costs. The web interface provides an improved user experience by simplifying the use of the models. The usage of machine learning in a computing platform that can use both on-premises clouds and public clouds constitutes a step forward in the adoption of serverless computing for scientific applications. © 2021 John Wiley & Sons, Ltd."
"International Conference on Applied Soft Computing and Communication Networks, ACN 2020","The proceedings contain 22 papers. The special focus in this conference is on Applied Soft Computing and Communication Networks. The topics include: Secure multimodal biometric recognition in principal component subspace; modelling video frames for object extraction using spatial correlation; algebraic modelling of a generic fog scenario for moving iot devices; p2p bot detection based on host behavior and big data technology; cloudsim exploration: A knowledge framework for cloud computing researchers; a comprehensive survey on big data technology based cybersecurity analytics systems; distributed denial of service (Ddos) attacks detection: A machine learning approach; an asynchronous leader-based neighbor discovery protocol in static wireless ad hoc networks; two-dimensional angle of arrival estimation using l-shaped array; preface; speech-based selective labeling of objects in an inventory setting; eeg-based emotion recognition and its interface with augmented reality; serverless deployment of a voice-bot for visually impaired; a novel approach to preserve drm for content distribution over p2p networks; icrest: International cross-reference to exchange-based stock trend prediction using long short-term memory; profile verification using blockchain; interference management technique for lte, wi-fi coexistence based on csi at the transmitter; localization in wireless sensor networks using a mobile anchor and subordinate nodes; intrusion detection using deep neural network with antirectifier layer; classification and evaluation of goal-oriented requirements analysis methods."
Query-driven video event processing for the internet multimedia things,"Advances in Deep Neural Network (DNN) techniques have revolutionized video analytics and unlocked the potential for querying and mining video event patterns. This paper details GNOSIS, an event processing platform to perform near-real-time video event detection in a distributed setting. GNOSIS follows a serverless approach where its component acts as independent microservices and can be deployed at multiple nodes. GNOSIS uses a declarative query-driven approach where users can write customize queries for spatiotemporal video event reasoning. The system converts the incoming video streams into a continuous evolving graph stream using machine learning (ML) and DNN models pipeline and applies graph matching for video event pattern detection. GNOSIS can perform both stateful and stateless video event matching. To improve Quality of Service (QoS), recent work in GNOSIS incorporates optimization techniques like adaptive scheduling, energy efficiency, and content-driven windows. This paper demonstrates the Occupational Health and Safety query use cases to show the GNOSIS efficacy. © The authors."
"International Conference on High Performance Computing, ISC High Performance 2021","The proceedings contain 35 papers. The special focus in this conference is on High Performance Computing. The topics include: H3: An Application-Level, Low-Overhead Object Store; Automatic Partitioning of MPI Operations in MPI+OpenMP Applications; heimdallr: Improving Compile Time Correctness Checking for Message Passing with Rust; potential of Interpreter Specialization for Data Analysis; refactoring for Performance with Semantic Patching: Case Study with Recipes; Negative Perceptions About the Applicability of Source-to-Source Compilers in HPC: A Literature Review; Automatic Tuning of Tensorflow’s CPU Backend Using Gradient-Free Optimization Algorithms; MSM: Multi-stage Multicuts for Scalable Image Clustering; OmniOpt – A Tool for Hyperparameter Optimization on HPC; Novel DNNs for Stiff ODEs with Applications to Chemically Reacting Flows; parallel/Distributed Intelligent Hyperparameters Search for Generative Artificial Neural Networks; machine Learning for Generic Energy Models of High Performance Computing Resources; Automation for Data-Driven Research with the NERSC Superfacility API; a Middleware Supporting Data Movement in Complex and Software-Defined Storage and Memory Architectures; an Operational Data Collecting and Monitoring Platform for Fugaku: System Overviews and Case Studies in the Prelaunch Service Period; An Explainable Model for Fault Detection in HPC Systems; a Scalable Cloud Deployment Architecture for High-Performance Real-Time Online Applications; Leveraging HW Approximation for Exploiting Performance-Energy Trade-offs Within the Edge-Cloud Computing Continuum; datashim and Its Applications in Bioinformatics; faaS and Curious: Performance Implications of Serverless Functions on Edge Computing Platforms; lettuce: PyTorch-Based Lattice Boltzmann Framework; Differentiated Performance in NoSQL Database Access for Hybrid Cloud-HPC Workloads; JUWELS Booster – A Supercomputer for Large-Scale AI Research."
Proceedings - SEKE 2021: 33rd International Conference on Software Engineering and Knowledge Engineering,The proceedings contain 114 papers. The topics discussed include: ArchiNet: a concept-token based approach for determining architectural change categories; analyzing open-source serverless platforms: characteristics and performance; HHML: a hierarchical hybrid modeling language for mode-based periodic controllers; patterns for reuse in production systems engineering; software design pattern analysis for micro-service architecture using queuing networks; multiclass classification of four types of UML diagrams from images using deep learning; on integrating ethicality in user stories; a collaborative forensic framework for detecting advanced persistent threats; an empirical study on the impact of class overlapin just-in-time software defect prediction; FSSRE: fusing semantic feature and syntactic dependencies feature for threat intelligence relation extraction; and AAMR: automated anomalous microservice ranking in cloud-native environment.
"Dorylus: Affordable, scalable, and accurate GNN training with distributed CPU servers and serverless threads","A graph neural network (GNN) enables deep learning on structured graph data. There are two major GNN training obstacles: 1) it relies on high-end servers with many GPUs which are expensive to purchase and maintain, and 2) limited memory on GPUs cannot scale to today’s billion-edge graphs. This paper presents Dorylus: a distributed system for training GNNs. Uniquely, Dorylus can take advantage of serverless computing to increase scalability at a low cost. The key insight guiding our design is computation separation. Computation separation makes it possible to construct a deep, bounded-asynchronous pipeline where graph and tensor parallel tasks can fully overlap, effectively hiding the network latency incurred by Lambdas. With the help of thousands of Lambda threads, Dorylus scales GNN training to billion-edge graphs. Currently, for large graphs, CPU servers offer the best performance per dollar over GPU servers. Just using Lambdas on top of Dorylus offers up to 2.75× more performance-per-dollar than CPU-only servers. Concretely, Dorylus is 1.22× faster and 4.83× cheaper than GPU servers for massive sparse graphs. Dorylus is up to 3.8× faster and 10.7× cheaper compared to existing sampling-based systems. © 2021 by The USENIX Association. All rights reserved."
"4th International Conference on Smart Computing and Informatics, SCI 2020",The proceedings contain 82 papers. The special focus in this conference is on Smart Computing and Informatics. The topics include: Log-Based Authentication for Cloud Environments; development of a Wireless Sensor Node for Electrical Power Distribution Monitoring System; CommonKADS and Ontology Reasoner: Bulky-Baggage Case Study; accelerated Sorting of Apples Based on Machine Learning; execution of Smart Contacts Concurrently Using Fine-Grain Locking and Asynchronous Functions; artificial Intelligence-Based Automatic Evaluation Engine; SmartRPL: Secure RPL Routing Protocol for Internet of Things Using Smart Contracts; customized Music Classification and Recommendation System Based on Classifiers of Neural Networks and Sensor Embedded on Smart Devices; recognizing the Faces from Surveillance Video; localization of Optic Cup-Disc in Retinal Images Using Morphological Filters for Glaucoma Detection; Region Labeling Based Brain Tumor Segmentation from MR Images; a Comparative Evaluation of Decomposition Methods Based on Pitch Estimation of Piano Notes; Application of Bat Optimization Algorithm for Power System Loss Reduction Using DSSSC; preface; pad Vending Machine with Cashless Payment; malaria Cell Detection Model; design and Analysis of Fractal Monopole Antennas for Multiband Wireless Applications; fake News Detection Using Text Analytics; an Extreme Learning Machine-Based Model for Cryptocurrencies Prediction; an Ensemble Approach for Intrusion Detection in Collaborative Attack Environment; a Decision Based Asymmetrically Trimmed Modified Geometric Mean Algorithm for the Removal of High Density Salt and Pepper Noise in Images and Videos; anti-poaching System Using Wireless Sensor Networking; performance Issues and Monitoring Mechanisms for Serverless IoT Applications—An Exploratory Study; detection of Pemphigus Vulgaris in Development Stage of Skin Erosion; fingerprint Genuinity Classification.
A Cloud-Based Computing Framework for Artificial Intelligence Innovation in Support of Multidomain Operations,"The DoD&#x2019;s artificial intelligence (AI) strategy requires the delivery of transformative and disruptive capabilities that impact the &#x201C;character of the future battlefield and the pace of threats&#x201D; that US forces must be prepared to handle. Candidate frameworks must also address key mission areas while enabling partnerships with the private sector, academia, and global allies. To meet these challenges, a flexible, cost-effective, and scalable computing infrastructure that incorporates cutting edge technologies and complies with stringent information assurance requirements is necessary. The DoD AI strategy mandates the agile employment of innovative AI capabilities that &#x201C;rapidly and iteratively&#x201D; execute experimentation with new operating concepts, and leverage lessons learned in subsequent experiments. Using cloud computing, we present a flexible approach to solve complex systems problems. Promoting &#x201C;rapid experimentation&#x201D; and collaboration on problems such as recursive algorithm implementation, deep learning, and inference in neural networks has enabled inherent advantages over existing computing frameworks. Leveraging the cloud to implement shared responsibility security models, serverless architectures, and high-performance virtual machines, aspects of the AI lifecycle including build, deploy, and monitor have resulted in an adaptable and scalable computing framework that is not only disruptive to the current computing paradigm but also promotes enhanced and productive collaboration. USGov"
"4th International Conference on Smart Computing and Informatics, SCI 2020",The proceedings contain 82 papers. The special focus in this conference is on Smart Computing and Informatics. The topics include: Log-Based Authentication for Cloud Environments; development of a Wireless Sensor Node for Electrical Power Distribution Monitoring System; CommonKADS and Ontology Reasoner: Bulky-Baggage Case Study; accelerated Sorting of Apples Based on Machine Learning; execution of Smart Contacts Concurrently Using Fine-Grain Locking and Asynchronous Functions; artificial Intelligence-Based Automatic Evaluation Engine; SmartRPL: Secure RPL Routing Protocol for Internet of Things Using Smart Contracts; customized Music Classification and Recommendation System Based on Classifiers of Neural Networks and Sensor Embedded on Smart Devices; recognizing the Faces from Surveillance Video; localization of Optic Cup-Disc in Retinal Images Using Morphological Filters for Glaucoma Detection; Region Labeling Based Brain Tumor Segmentation from MR Images; a Comparative Evaluation of Decomposition Methods Based on Pitch Estimation of Piano Notes; Application of Bat Optimization Algorithm for Power System Loss Reduction Using DSSSC; preface; pad Vending Machine with Cashless Payment; malaria Cell Detection Model; design and Analysis of Fractal Monopole Antennas for Multiband Wireless Applications; fake News Detection Using Text Analytics; an Extreme Learning Machine-Based Model for Cryptocurrencies Prediction; an Ensemble Approach for Intrusion Detection in Collaborative Attack Environment; a Decision Based Asymmetrically Trimmed Modified Geometric Mean Algorithm for the Removal of High Density Salt and Pepper Noise in Images and Videos; anti-poaching System Using Wireless Sensor Networking; performance Issues and Monitoring Mechanisms for Serverless IoT Applications—An Exploratory Study; detection of Pemphigus Vulgaris in Development Stage of Skin Erosion; fingerprint Genuinity Classification.
1st EAGE Digital Subsurface Conference in Latin America,"The proceedings contain 13 papers. The topics discussed include: advanced interpretation of wireline data with machine learning using multiple models, augmented learning population and geology; accelerating E&P decisions by applying artificial intelligence and big data analytics to unstructured data; object-oriented optimization for small- and large-scale seismic inversion procedures; FWI performance improvement with the use of wavelet transforms; enhancing lithology classification with the help of AI: a machine learning approach; the benefits and applications of cloud computing in energy technology solutions; time series clustering, sequence stratigraphy, and ensemble machine learning for shear velocity prediction in conventional reservoirs; and going serverless: geostatistical inversion on AWS."
Towards Demystifying Serverless Machine Learning Training,"The appeal of serverless (FaaS) has triggered a growing interest on how to use it in data-intensive applications such as ETL, query processing, or machine learning (ML). Several systems exist for training large-scale ML models on top of serverless infrastructures (e.g., AWS Lambda) but with inconclusive results in terms of their performance and relative advantage over ""serverful""infrastructures (IaaS). In this paper we present a systematic, comparative study of distributed ML training over FaaS and IaaS. We present a design space covering design choices such as optimization algorithms and synchronization protocols, and implement a platform, LambdaML, that enables a fair comparison between FaaS and IaaS. We present experimental results using LambdaML, and further develop an analytic model to capture cost/performance tradeoffs that must be considered when opting for a serverless infrastructure. Our results indicate that ML training pays off in serverless only for models with efficient (i.e., reduced) communication and that quickly converge. In general, FaaS can be much faster but it is never significantly cheaper than IaaS. © 2021 ACM."
DevOps and Quality Management in Serverless Computing: The RADON Approach,"The onset of microservices and serverless computer solutions has forced an ever-increasing demand for tools and techniques to establish and maintain the quality of infrastructure code, the blueprint that drives the operationalization of large-scale software systems. In the EU H2020 project RADON, we propose a machine-learning approach to elaborate and evolve Infrastructure-as-Code as part of a full-fledged industrial-strength DevOps pipeline. This paper illustrates RADON and shows our research roadmap. © 2021, Springer Nature Switzerland AG."
Bringing AI to the edge: A formal M&S specification to deploy effective IoT architectures,"Internet of Things applications are based on ubiquitous networks of multiple distributed devices, with limited computing resources and power, capable of collecting and storing data from heterogeneous sources in real-time. To avoid network saturation and delays, new architectures are needed to provide real-time Big Data and data analytics capabilities at the edge of the network, where energy efficiency needs to be considered to ensure a sustainable and effective deployment in areas of human activity. In this research, we present an IoT model based on the principles of Model-Based Systems Engineering. It covers the description of the entire architecture, from IoT devices to the processing units in edge data centres, and includes the location-awareness of user equipment, network, and computing infrastructures to optimise federated resource management in terms of delay and power consumption. We present a framework to assist the dimensioning and the dynamic operation of IoT data stream analytics applications. Abbreviations: ADAS Advanced Driver Assistance System. 20, 21, 24AI Artificial Intelligence. 2, 24ANN Artificial Neural Network. 2, 21AP Access Point. 5, 10, 11, 12, 13, 17, 18, 19, 20CNF Core Network Function. 5DEVS Discrete Event System Specification. 3, 5, 6, 7, 9, 10, 11, 12, 15, 16, 17, 18, 20, 21, 24, 27, 28EDC Edge Data Centre. 2, 3, 5, 6, 9, 10, 12, 13, 20, 21, 22, 23, 25FaaS Function-as-a-Service. 3, 4, 5, 6FDD Frequency Division Duplexing. 11, 18, 19FSPL Free-Space Path Loss. 20GPU Graphics Processing Unit. 2, 21IoT Internet of Things. 2, 3, 4, 5, 6, 14, 19, 23, 24ISP Internet Service Provider. 5, 10M&S Modelling and Simulation. 3, 24M&S&O Modelling, Simulation, and Optimisation. 21MBSE Model-Based Systems Engineering. 3, 4, 5, 24MCS Modulation and Codification Scheme. 12MDC Micro Data Centre. 2ML Machine Learning. 2, 20, 24, 25NR 5G New Radio. 12P2P Point-to-Point. 5, 10PBCH Physical Broadcast Channel. 19PDCCH Physical Downlink Control Channel. 19PDSCH Physical Downlink Shared Channel. 19PSS Primary Synchronisation Signal. 11, 14PU Processing Unit. 7, 9, 21, 22, 23, 24, 25PUCCH Physical Uplink Control Channel. 19PUSCH Physical Uplink Shared Channel. 19QoS Quality of Service. 2, 4, 5, 6, 12, 24RAN Radio Access Network. 5, 10, 13, 16, 17, 20SDN Software-Defined Network. 5, 10SNR Signal-to-Noise Ratio. 11, 12, 14, 17UE User Equipment. 4, 5, 6, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25WSN Wireless Sensor Network. 4. © 2021 Operational Research Society."
Optimized container scheduling for data-intensive serverless edge computing,"Operating data-intensive applications on edge systems is challenging, due to the extreme workload and device heterogeneity, as well as the geographic dispersion of compute and storage infrastructure. Serverless computing has emerged as a compelling model to manage the complexity of such systems, by decoupling the underlying infrastructure and scaling mechanisms from applications. Although serverless platforms have reached a high level of maturity, we have found several limiting factors that inhibit their use in an edge setting. This paper presents a container scheduling system that enables such platforms to make efficient use of edge infrastructures. Our scheduler makes heuristic trade-offs between data and computation movement, and considers workload-specific compute requirements such as GPU acceleration. Furthermore, we present a method to automatically fine-tune the weights of scheduling constraints to optimize high-level operational objectives such as minimizing task execution time, uplink usage, or cloud execution cost. We implement a prototype that targets the container orchestration system Kubernetes, and deploy it on an edge testbed we have built. We evaluate our system with trace-driven simulations in different infrastructure scenarios, using traces generated from running representative workloads on our testbed. Our results show that (a) our scheduler significantly improves the quality of task placement compared to the state-of-the-art scheduler of Kubernetes, and (b) our method for fine-tuning scheduling parameters helps significantly in meeting operational goals. © 2020"
Automatic Tuning of Hyperparameters for Neural Networks in Serverless Cloud,"Deep Neural Networks are used to solve the most challenging world problems. In spite of the numerous advancements in the field, most of the models are being tuned manually. Experienced Data Scientists have to manually optimize hyperparameters, such as dropout rate, learning rate or number of neurons for Big Data applications. We have implemented a flexible automatic real-time hyperparameter tuning methodology. It works for arbitrary models written in Python and Keras. We also utilized state of the art Cloud services such as trigger based serverless computing (Lambda), and advanced GPU instances to implement automation, reliability and scalability.The existing tuning libraries, such as hyperopt, Scikit-Optimize or SageMaker, require developers to provide a list of hyperparameters and the range of their values manually. Our novel approach detects potential hyperparameters automatically from the source code, updates the original model to tune the parameters, runs the evaluation in the Cloud on spot instances, finds the optimal hyperparameters, and saves the results in the No-SQL database. The methodology can be applied to numerous Big Data Machine Learning systems. © 2020 IEEE."
Adaptive and Efficient Streaming Time Series Forecasting with Lambda Architecture and Spark,"The rise of the Internet of Things (IoT) devices and the streaming platform has tremendously increased the data in motion or streaming data. It incorporates a wide variety of data, for example, social media posts, online gamers in-game activities, mobile or web application logs, online e-commerce transactions, financial trading, or geospatial services. Accurate and efficient forecasting based on real-time data is a critical part of the operation in areas like energy utility consumption, healthcare, industrial production, supply chain, weather forecasting, financial trading, agriculture, etc. Statistical time series forecasting methods like Autoregression (AR), Autoregressive integrated moving average (ARIMA), and Vector Autoregression (VAR), face the challenge of concept drift in the streaming data, i.e., the properties of the stream may change over time. Another challenge is the efficiency of the system to update the Machine Learning (ML) models which are based on these algorithms to tackle the concept drift. In this paper, we propose a novel framework to tackle both of these challenges. The challenge of adaptability is addressed by applying the Lambda architecture to forecast future state based on three approaches simultaneously: batch (historic) data-based prediction, streaming (real-time) data-based prediction, and hybrid prediction by combining the first two. To address the challenge of efficiency, we implement a distributed VAR algorithm on top of the Apache Spark big data platform. To evaluate our framework, we conducted experiments on streaming time series forecasting with four types of data sets of experiments: data without drift (no drift), data with gradual drift, data with abrupt drift and data with mixed drift. The experiments show the differences of our three forecasting approaches in terms of accuracy and adaptability. © 2020 IEEE."
Soil Analysis and its Type Prediction with Speech Enabled Output using IoT and AWS,"This paper proposes a new technique which can predict soil type and gives correct information to the farmers in audio format for improvised cultivation. It collects different soil parameters such as soil temperature, moisture and nitrogen, phosphorous and potassium (NPK) values present in the soil by taking the help of different sensors and predict the soil type using Random Forest Classifier, Support Vector Machine and Linear Regression Algorithms. From the comparison of all the mentioned machine learning algorithms, it is found that Random Forest Classifier gives the best soil type prediction with least Root Mean Square Error (RMSE) value. Using AWS technique, the predicted soil type information which is given in text format is converted to audio format which is easily understand by the farmers. A serverless application has been utilized to convey the information about the soil type to the farmers for better cultivation. © 2020 IEEE."
Implications of Public Cloud Resource Heterogeneity for Inference Serving,"We are witnessing an increasing trend towards using Machine Learning (ML) based prediction systems, spanning across different application domains, including product recommendation systems, personal assistant devices, facial recognition, etc. These applications typically have diverse requirements in terms of accuracy and response latency, that can be satisfied by a myriad of ML models. However, the deployment cost of prediction serving primarily depends on the type of resources being procured, which by themselves are heterogeneous in terms of provisioning latencies and billing complexity. Thus, it is strenuous for an inference serving system to choose from this confounding array of resource types and model types to provide low-latency and cost-effective inferences. In this work we quantitatively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource offerings. Our evaluation shows that, prior work does not solve the problem from both dimensions of model and resource heterogeneity. Hence, to holistically address this problem, we need to solve the issues that arise from combining both model and resource heterogeneity towards optimizing for application constraints. Towards this, we discuss the design implications of a self-managed inference serving system, which can optimize for application requirements based on public cloud resource characteristics. © 2020 ACM."
Towards Federated Learning using FaaS Fabric,"Federated learning (FL) enables resource-constrained edge devices to learn a shared Machine Learning (ML) or Deep Neural Network (DNN) model, while keeping the training data local and providing privacy, security, and economic benefits. However, building a shared model for heterogeneous devices such as resource-constrained edge and cloud makes the efficient management of FL-clients challenging. Furthermore, with the rapid growth of FL-clients, the scaling of FL training process is also difficult. In this paper, we propose a possible solution to these challenges: federated learning over a combination of connected Function-as-a-Service platforms, i.e., FaaS fabric offering a seamless way of extending FL to heterogeneous devices. Towards this, we present FedKeeper, a tool for efficiently managing FL over FaaS fabric. We demonstrate the functionality of FedKeeper by using three FaaS platforms through an image classification task with a varying number of devices/clients, different stochastic optimizers, and local computations (local epochs). © 2020 ACM."
Middleware 2020 - Proceedings of the 2020 21st International Middleware Conference,The proceedings contain 30 papers. The topics discussed include: prebaking functions to warm the serverless cold start; resilient cloud-based replication with low latency; practical active revocation; secureTF: a secure tensorflow framework; on delivery guarantees in distributed content-based publish/subscribe systems; MATCH: a decentralized middleware for fair matchmaking in peer-to-peer markets; PipeTune: pipeline parallelism of hyper and system parameters tuning for deep learning clusters; fast training of deep learning models over multiple GPUs; and FLeet: online federated learning via staleness awareness and performance prediction.
"Proceedings - 2020 IEEE 22nd International Conference on High Performance Computing and Communications, IEEE 18th International Conference on Smart City and IEEE 6th International Conference on Data Science and Systems, HPCC-SmartCity-DSS 2020",The proceedings contain 183 papers. The topics discussed include: design of direct read from sparse segments in MPI-IO; descriptive and predictive analysis of aggregating functions in serverless clouds: the case of video streaming; a proactive uncertainty driven model for data synopses management in pervasive applications; on-line traffic scheduling optimization in IEEE 802.1Qch based time-sensitive networks; multi-layer and heterogeneous resource management in SDN-based space-terrestrial integrated networks; structure preserved graph reordering for fast graph processing without the pain; an efficient approach to vectorize the hybrid breadth-first search; a novel developer portrait model based on Bert-capsule network; job placement strategy with opportunistic resource sharing for distributed deep learning clusters; and batched pattern-aware cache management strategy for astronomical time series sub-images retrieval.
Toci: Computational Intelligence in an Energy Management System,"Building energy management and smart energy efficiency are two important application areas for computational intelligence systems. This work describes how we create computational intelligence (CI) in a building energy management system that learns about typical energy use in the building environment and alerts building managers when it detects unusual operating conditions. The CI system is part of a more extensive energy management system, named Tornado, and comprises multiple buildings, various energy forms, and roughly one hundred sensors. The Tornado computational intelligence system (short: Toci) executes both in the cloud and at the edge, on IoT devices deployed in the managed buildings. The machine learning that underlies the alerts that Toci generates runs in the cloud, but learned models are also deployed at the edge. Computational intelligence is not entirely lost when network connectivity is interrupted. One key aspect of our system is that it implemented using the serverless computing paradigm, making our system both highly scalable and efficient. In the paper, we describe several practical applications of TOCI and demonstrate that Toci can detect unusual operating conditions relevant in practice. Taking weather conditions into account, Toci can identify failing inverters in PV installations, despite the high normal fluctuation of solar power production. Due to the serverless architecture, Toci scales very well, and we demonstrate that this is achieved at a low monetary cost. © 2020 IEEE."
"PODPAC: open-source Python software for enabling harmonized, plug-and-play processing of disparate earth observation data sets and seamless transition onto the serverless cloud by earth scientists","In this paper, we present the Pipeline for Observational Data Processing, Analysis, and Collaboration (PODPAC) software. PODPAC is an open-source Python library designed to enable widespread exploitation of NASA earth science data by enabling multi-scale and multi-windowed access, exploration, and integration of available earth science datasets to support analysis and analytics; automatic accounting for geospatial data formats, projections, and resolutions; simplified implementation and parallelization of geospatial data processing routines; standardized sharing of data and algorithms; and seamless transition of algorithms and data products from local development to distributed, serverless processing on commercial cloud computing environments. We describe the key elements of PODPAC’s architecture, including Nodes for unified encapsulation of disparate scientific data sources; Algorithms for plug-and-play processing and harmonization of multiple data source Nodes; and Lambda functions for serverless execution and sharing of new data products via the cloud. We provide an overview of our open-source code implementation and testing process for development and deployment of PODPAC. We describe our interactive, JupyterLab-based end-user documentation including quick-start examples and detailed use case studies. We conclude with examples of PODPAC’s application to: encapsulate data sources available on Amazon Web Services (AWS) Open Data repository; harmonize processing of multiple earth science data sets for downscaling of NASA Soil Moisture Active Passive (SMAP) soil moisture data; and deploy a serverless SMAP-based drought monitoring application for use access from mobile devices. We postulate that PODPAC will also be an effective tool for wrangling and standardizing massive earth science data sets for use in model training for machine learning applications. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature."
Predictive Cyber Foraging for Visual Cloud Computing in Large-Scale IoT Systems,"Cyber foraging has been shown to be especially effective for augmenting low-power Internet-of-Thing (IoT) devices by offloading video processing tasks to nearby edge/cloud computing servers. Factors such as dynamic network conditions, concurrent user access, and limited resource availability, cause offloading decisions that negatively impact overall processing throughput and end-user delays. Moreover, edge/cloud platforms currently offer both Virtual Machine (VM) and serverless computing pricing models, but many existing edge offloading approaches only investigate single VM-based offloading performance. In this paper, we propose a predictive (NP-complete) scheduling-based offloading framework and a heuristic-based counterpart that use machine learning to dynamically decide what combinations of functions or single VM needs to be deployed so that tasks can be efficiently scheduled. We collected over 10,000 network and device traces in a series of realistic experiments relating to a protest crowds incident management application. We then evaluated the practicality of our predictive cyber foraging approach using trace-driven simulations for up to 1000 devices. Our results indicate that predicting single VM offloading costs: (a) leads to near-optimal scheduling in 70% of the cases for service function chaining, and (b) offers a 40% gain in performance over traditional baseline estimation techniques that rely on simple statistics for estimations in the case of single VM-offloading. Considering a series of visual computing offloading scenarios, we also validate our approach benefits of using online versus offline machine learning models for predicting offloading delays. © 2004-2012 IEEE."
Recent Developments in the Design and Implementation of Programming Languages - Gabbrielli's Festschrift,"The proceedings contain 12 papers. The topics discussed include: locally static, globally dynamic session types for active objects; a formal analysis of the bitcoin protocol; deconfined intersection types in java; towards a unifying framework for tuning analysis precision by program transformation; the servers of serverless computing: a formal revisitation of functions as a service; a logic programming approach to reaction systems; abstract interpretation, symbolic execution and constraints; the standard model for programming languages: the birth of a mathematical theory of computation; a concurrent language for argumentation: preliminary notes; Inseguendo Fagiani Selvatici: partial order reduction for guarded command languages; and derivation of constraints from machine learning models and applications to security and privacy."
Batch: Machine learning inference serving on serverless platforms with adaptive batching,"Serverless computing is a new pay-per-use cloud service paradigm that automates resource scaling for stateless functions and can potentially facilitate bursty machine learning serving. Batching is critical for latency performance and cost-effectiveness of machine learning inference, but unfortunately it is not supported by existing serverless platforms due to their stateless design. Our experiments show that without batching, machine learning serving cannot reap the benefits of serverless computing. In this paper, we present BATCH, a framework for supporting efficient machine learning serving on serverless platforms. BATCH uses an optimizer to provide inference tail latency guarantees and cost optimization and to enable adaptive batching support. We prototype BATCH atop of AWS Lambda and popular machine learning inference systems. The evaluation verifies the accuracy of the analytic optimizer and demonstrates performance and cost advantages over the state-of-the-art method MArk and the state-of-the-practice tool SageMaker. © 2020 IEEE."
Poster: Lambda architecture for robust condition based maintenance with simulated failure modes,"Condition based maintenance (CBM) is increasingly seen as a promising approach for addressing downtime issues which are a common occurrence in the manufacturing industry and are a major cause of lost productivity. However, it has been a challenge to develop a generic CBM solution that works for all assets since each asset has unique sources of noise. This mandates use of manual diagnostics to custom tailor a solution for each asset for accurate failure mode identification (FMI). This problem is further compounded by the scarcity of failure data. In this paper, we propose a lambda architecture for FMI of industrial assets that achieves low initial deployment cost while securing a reasonable classification accuracy. The lambda architecture consists of a light-compute edge node, such as Raspberry Pi, that processes high-speed vibration data in real-time to extract useful features and applies a deep-learning (DL) engine which is trained in a cloud platform, such as AWS. In addition, we also incorporate a failure modes' feature simulator so that DL models can adapt to different industrial assets without costly failure data collection. Finally, experimental results are provided using the bearings' failures dataset validating the proposed cost-effective CBM architecture with high accuracy and scalability. © 2020 IEEE."
Serverless straggler mitigation using error-correcting codes,"Inexpensive cloud services, such as serverless computing, are often vulnerable to straggling nodes that increase the end-to-end latency for distributed computation. We propose and implement simple yet principled approaches for straggler mitigation in serverless systems for matrix multiplication and evaluate them on several common applications from machine learning and high-performance computing. The proposed schemes are inspired by error-correcting codes and employ parallel encoding and decoding over the data stored in the cloud using serverless workers. This creates a fully distributed computing framework without using a master node to conduct encoding or decoding, which removes the computation, communication and storage bottleneck at the master. On the theory side, we establish that our proposed scheme is asymptotically optimal in terms of decoding time and provide a lower bound on the number of stragglers it can tolerate with high probability. Through extensive experiments, we show that our scheme outperforms existing schemes such as speculative execution and other coding theoretic methods by at least 25%. © 2020 IEEE"
"Deep learning architectures in emerging cloud computing architectures: Recent development, challenges and next research trend","The challenges of the conventional cloud computing paradigms motivated the emergence of the next generation cloud computing architectures. The emerging cloud computing architectures generate voluminous amount of data that are beyond the capability of the shallow intelligent algorithms to process. Deep learning algorithms, with their ability to process large-scale datasets, have recently started gaining tremendous attentions from researchers to solve problem in the emerging cloud computing architectures. However, no comprehensive literature review exists on the applications of deep learning architectures to solve complex problems in emerging cloud computing architectures. To fill this gap, we conducted a comprehensive literature survey on the applications of deep learning architectures in emerging cloud computing architectures. The survey shows that the adoption of deep learning architectures in emerging cloud computing architectures are increasingly becoming an interesting research area. We introduce a new taxonomy of deep learning architectures for emerging cloud computing architectures and provide deep insights into the current state-of-the-art active research works on deep learning to solve complex problems in emerging cloud computing architectures. The synthesis and analysis of the articles as well as their limitation are presented. A lot of challenges were identified in the literature and new future research directions to solve the identified challenges are presented. We believed that this article can serve as a reference guide to new researchers and an update for expert researchers to explore and develop more deep learning applications in the emerging cloud computing architectures. © 2020 Elsevier B.V."
PrivacyFL: A Simulator for Privacy-Preserving and Secure Federated Learning,"Federated learning is a technique that enables distributed clients to collaboratively learn a shared machine learning model without sharing their training data. This reduces data privacy risks, however, privacy concerns still exist since it is possible to leak information about the training dataset from the trained model's weights or parameters. Therefore, it is important to develop federated learning algorithms that train highly accurate models in a privacy-preserving manner. Setting up a federated learning environment, especially with security and privacy guarantees, is a time-consuming process with numerous configurations and parameters that can be manipulated. In order to help clients ensure that collaboration is feasible and to check that it improves their model accuracy, a real-world simulator for privacy-preserving and secure federated learning is required. In this paper, we introduce PrivacyFL, which is an extensible, easily configurable, and scalable simulator for federated learning environments. Its key features include latency simulation, robustness to client departure/failure, support for both centralized (with one or more servers) and decentralized (serverless) learning, and configurable privacy and security mechanisms based on differential privacy and secure multiparty computation (MPC). In this paper, we motivate our research, describe the architecture of the simulator and associated protocols, and discuss its evaluation in numerous scenarios that highlight its wide range of functionality and its advantages. Our paper addresses a significant real-world problem: checking the feasibility of participating in a federated learning environment under a variety of circumstances. It also has a strong practical impact because organizations such as hospitals, banks, and research institutes, which have large amounts of sensitive data and would like to collaborate, would greatly benefit from having a system that enables them to do so in a privacy-preserving and secure manner. © 2020 Owner/Author."
Scalable IoT solution using cloud services - An automobile industry use case,"The role of IoT and related internet-based applications in otherwise mechanical devices to monitor, manage and enhance the performance of the same is quite widespread now. Almost all public cloud service providers provide scalable, fully managed and elastic IoT related services. The data flows from these services are essentially streaming and can be consumed for further use in various predictive, descriptive and visualization modules. The cloud platforms enable ingestion, transformation and usage of the data by providing streaming, machine learning and sharable visualization services. This ecosystem greatly reduces the time to create IoT based minimum viable product creation which in turn enhances the business value realization cycle. The effect of cycle time reduction to design, architect and develop IoT solutions leads to a rapid improvement of business lead time and makes it easier for businesses to gain from the data insights and plan the next course of action. In this paper, one such enterprise graded use case is explored, in which the Azure IoT platform in terms of the offerings and associated ecosystem of Azure Stream Analytics and Azure Machine learning services are explained. This paper covers design, architecture, development and deployment of the solution prepared and how the same is monitored once in production. Security is a very important aspect of the same and here the security architecture is being explored. A conclusion is presented with the scope of future enhancements using auto ML services in serverless platforms to enable real-time automated decision making augmented with human expertise and intelligence. © 2020 IEEE."
Migrating Large Deep Learning Models to Serverless Architecture,"Serverless computing platform is emerging as a solution for event-driven artificial intelligence applications. Function-as-a-Service (FaaS) using serverless computing paradigm provides high performance and low cost solutions for deploying such applications on cloud while minimizing the operational logic. Using FaaS for efficient deployment of complex applications, such as natural language processing (NLP) and image processing, containing large deep learning models will be an advantage. However, constrained resources and stateless nature of FaaS offers numerous challenges while deploying such applications. In this work, we discuss the methodological suggestions and their implementation for deploying pre-trained large size machine learning and deep learning models on FaaS. We also evaluate the performance and deployment cost of an enterprise application, consisting of suite of deep vision preprocessing algorithms and models, on VM and FaaS platform. Our evaluation shows that migration from monolithic to FaaS platform significantly improves the performance of the application at a reduced cost. © 2020 IEEE."
"Proceedings - 2020 IEEE 13th International Conference on Cloud Computing, CLOUD 2020",The proceedings contain 84 papers. The topics discussed include: RSDS: getting system call whitelist for container through dynamic and static analysis; Lambdata: optimizing serverless computing by making data intents explicit; CFP: a cross-layer recommender system with fine-grained preloading for short video streaming at network edge; proactive container auto-scaling for cloud native machine learning services; TensorExpress: in-network communication scheduling for distributed deep learning; energy efficient decentralized geographical load balancing via dynamic deferral of workload; optimal application deployment in mobile edge computing environment; FedMax: enabling a highly-efficient federated learning framework; and analysis of SQL workloads on an enterprise datalake.
Evaluating webassembly enabled serverless approach for edge computing,"The edge computing ecosystem has been evolving in the last few years. There have been different architectural patterns proposed to implement edge computing solutions. This paper focuses on serverless edge computing architecture and evaluates webassembly based approach for the same. The current state of serverless edge computing is explained followed by providing high level conceptual overview of webassembly. We-bassembly performance is evaluated against native and container based applications using the current toolchain supported for ARM architecture. Benchmarking is done for different categories of applications like compute intensive, memory intensive, file I/O intensive and a simple image classification - machine learning application. This paper describes the experimental setup, discusses the performance results and provides the conclusion. © 2020 IEEE."
A machine learning model on virtual university of senegal’s educational data based on lambda architecture.,"Nowadays, a new form of learning has emerged in higher education. This is e-Learning. Lessons are taught on a Learning Content Management Systems (LCMS). These platforms generate a large variety of data at very high speed. This massive data comes from the interactions between the system and the users and between the users themselves (Learners, Tutors, Teachers, administrative Agents). Since 2013, UVS (Virtual University of Senegal), a digital university that offers distance learning through Moodle and Blackboard Collaborate platforms, has emerged. In terms of statistics, it has 29340 students, more than 400 active Tutors and 1000 courses. As a result, a large volume of data is generated on its learning platforms. In this article, we have set up an architecture allowing us to execute all types of queries on all data from platforms (historical data and real-time data) in order to set up intelligent systems capable of improving learning in this university. We then set up a machine learning model as a use case which is based on multiple regression in order to predict the most influential learning objects on the learners’ final mark according to his learning activities. © 2020 Institute of Advanced Engineering and Science (IAES). All Rights Reserved."
Context agnostic trajectory prediction based on λ-architecture,"Predicting the next position of movable objects has been a problem for at least the last three decades, referred to as ‘trajectory prediction’. In our days, the vast amounts of data being continuously produced add the big data dimension to the trajectory prediction problem, which we are trying to tackle by creating a λ-Architecture based analytics platform. This platform performs both batch and stream analytics tasks and then combines them to perform analytical tasks that cannot be performed by analyzing any of these layers by itself. The biggest benefit of this platform is its context agnostic trait, which allows us to use it for any use case, as long as a time-stamped geo-location stream is provided. The experimental results presented prove that each part of the λ-Architecture performs well at certain targets, making a combination of these parts a necessity in order to improve the overall accuracy and performance of the platform. © 2019 Elsevier B.V."
Event-driven framework for detecting unusual patterns in AAL environments,"An aging population has motivated research into Ambient Assisted Living (AAL) with the aim of supporting people to continue to live in their homes as they age or with chronic health problems. As part of this work, some researchers have focused on identifying and reporting daily activities of individuals at home in order to try to reduce the workload on caregivers and health professionals. Such an environment is usually monitored by non-wearable sensors that collect a vast amount of data. The use of this data requires computational methods that can process it in a reasonable time. This paper proposes an event-driven framework to detect unusual patterns in AAL environments. A Fog-Cloud paradigm and Lambda architecture are adopted as the framework to support computational solutions to deal with the volume of data, and machine learning techniques are used for recognition of daily activities. The framework was evaluated through a case study based on data collected in a real environment. Results point to the feasibility of the proposal. © 2020 IEEE."
SLATE: Managing heterogeneous cloud functions,"This paper presents SLATE, a fully-managed, heterogeneous Function-as-a-Service (FaaS) system for deploying serverless functions onto heterogeneous cloud infrastructures. We extend the traditional homogeneous FaaS execution model to support heterogeneous functions, automating and abstracting runtime management of heterogeneous compute resources in order to improve cloud tenant accessibility to specialised, accelerator resources, such as FPGAs and GPUs. In particular, we focus on the mechanisms required for heterogeneous scaling of deployed function instances to guarantee latency objectives while minimising cost. We develop a simulator to validate and evaluate our approach, considering case-study functions in three application domains: machine learning, bio-informatics, and physics. We incorporate empirically derived performance models for each function implementation targeting a hardware platform with combined computational capacity of 24 FPGAs and 12 CPU cores. Compared to homogeneous CPU and homogeneous FPGA functions, simulation results achieve respectively a cost improvement for non-uniform task traffic of up to 8.7 times and 1.7 times, while maintaining specified latency objectives. © 2020 IEEE."
Refactoring of Neural Network Models for Hyperparameter Optimization in Serverless Cloud,"Machine Learning and Neural Networks in particular have become hot topics in Computer Science. The recent 2019 Turing award to the forefathers of Deep Learning and AI - Yoshua Bengio, Geoffrey Hinton, and Yann LeCun proves the importance of the technology and its effect on science and industry. However, we have realized that even nowadays, the state of the art methods require several manual steps for neural network hyperparameter optimization. Our approach automates the model tuning by refactoring the original Python code using open-source libraries for processing. We were able to identify hyperparameters by parsing the original source and analyzing it. Given these parameters, we refactor the model, add the state of the art optimization library calls, and run the updated code in the Serverless Cloud. Our approach has proven to eliminate manual steps for an arbitrary TensorFlow and Keras tuning. We have created a tool called OptPar which automatically refactors an arbitrary Deep Neural Network optimizing its hyperparameters. Such a transformation can save hours of time for Data Scientists, giving them an opportunity to concentrate on designing their Machine Learning algorithms. © 2020 ACM."
Le Taureau: Deconstructing the Serverless Landscape & A Look Forward,"Akin to the natural evolution of programming in assembly language to high-level languages, serverless computing represents the next frontier in the evolution of cloud computing: bare metal -> virtual machines -> containers -> serverless. The genesis of serverless computing can be traced back to the fundamental need of enabling a programmer to singularly focus on writing application code in a high-level language and isolating all facets of system management (for example, but not limited to, instance selection, scaling, deployment, logging, monitoring, fault tolerance and so on). This is particularly critical in light of today's, increasingly tightening, time-to-market constraints. Currently, serverless computing is supported by leading public cloud vendors, such as AWS Lambda, Google Cloud Functions, Azure Cloud Functions and others. While this is an important step in the right direction, there are many challenges going forward. For instance, but not limited to, how to enable support for dynamic optimization, how to extend support for stateful computation, how to efficiently bin-pack applications, how to support hardware heterogeneity (this will be key especially in light of the emergence of hardware accelerators for deep learning workloads). Inspired by Picasso's Le Taureau, in the tutorial proposed herein, we shall deconstruct evolution of serverless - - the overarching intent being to facilitate better understanding of the serverless landscape. This, we hope, would help push the innovation frontier on both fronts, the paradigm itself and the applications built atop of it. © 2020 Association for Computing Machinery."
Potential Bottleneck and Measuring Performance of Serverless Computing: A Literature Study,"Trending form of cloud computing is Serverless computing, where developer just needs to focus on his code rather than worrying about server management. In serverless computing, application is nothing but collection of one or more functions, written for specific business functionality, which triggers on an event. There are various cloud service providers, i.e. Amazon, Microsoft, Google, IBM, etc. who provide serverless services, on pay as you use and auto scalable solution to execute the application code as a function. The developer just needs to upload the code for execution. The performance of the serverless computing may vary due to dynamic configuration of the solution, technologies and different technology used by the service provider.This paper reviews various past and recent work in the serverless computing to identify possible bottlenecks and the scope of measuring performance of serverless computing. It will also put some light to leverage machine learning in various possible ways to do performance engineering for future research. © 2020 IEEE."
Prognostics by classifying degradation stage on lambda architecture,"To enhance the reliability and availability of an asset in its life, predicting the remaining useful life of an asset is strongly encouraged by assessing the extent of deviation or degradation of the asset's monitored parameters from its expected normal operating conditions. Although intelligent fault prognostic techniques such as machine learning and artificial neural networks have been applied in modern industries, application in actual industrial conditions requires that the forecasting process is revealed and more descriptive. To investigate the issue and increase the accuracy, this paper proposes an additional technique that can be further applied to any recent intelligent prognostic methods. The proposed method consists of two steps. First, the entire training set is divided into several degradation stages before regression using a heuristic approach and then the regression results are synthesized for each stage. The proposed method will increase the monotonicity of the predictive parameters, thus helping improve the predictive model's accuracy. To demonstrate the hypothesis, real condition monitoring data of high-pressure LNG pump and acceleration experimental data of a rotating machine is used for an experiment. Moreover, a system in which the proposed method can be appropriately executed is introduced with Lambda architecture. Finally, by demonstrating that the proposed method is capable of parallel computing, it is proven suitable for use in the proposed large-scale distributed processing system. © 2020 IEEE."
Proceedings of CISTI 2020 - 15th Iberian Conference on Information Systems and Technologies,The proceedings contain 366 papers. The topics discussed include: using machine learning for cognitive robotic process automation (RPA); acoustic monitoring system for teacher and student engagement evaluation; patient-centered healthcare monitoring in an outpatient scenario; serverless based control and monitoring for search and rescue robots; social engineering and the dangers of phishing; graphical semantic authentication; Moocs and other technological proposals in the transformation of education; performance evaluation of the virtualization environment of a microservices-based payroll system; enterprise architecture: critical factors and implementation; and processing UAV based RGB data to identify land cover with focus on small water body.
Federated Learning with Mutually Cooperating Devices: A Consensus Approach Towards Server-Less Model Optimization,"Federated learning (FL) is emerging as a new paradigm for training a machine learning model in cooperative networks. The model parameters are optimized collectively by large populations of interconnected devices, acting as cooperative learners that exchange local model updates with the server, rather than user data. The FL framework is however centralized, as it relies on the server for fusion of the model updates and as such it is limited by a single point of failure. In this paper we propose a distributed FL approach that performs a decentralized fusion of local model parameters by leveraging mutual cooperation between the devices and local (in-network) data operations via consensus-based methods. Communication with the server can be partially, or fully, replaced by in-network operations, scaling down the traffic load on the server as well as paving the way towards a fully serverless FL approach. This proposal also lays the groundwork for integration of FL methods within future (beyond 5G) wireless networks characterized by distributed and decentralized connectivity. The proposed algorithms are implemented and published as open source. They are also designed and verified by experimental data. © 2020 IEEE."
Cost-Effective Malware Detection as a Service over Serverless Cloud Using Deep Reinforcement Learning,"The current trends of cloud computing in general, and serverless computing in particular, affect multiple aspects of organizational activity. Organizations of all sizes are transitioning parts of their operations off-premise in order to reduce costs and scale their operations more efficiently. The field of network security is no exception, with many organizations taking advantage of the distributed and scalable cloud environment. Since the charging model for serverless computing is ""pay as you go"" (i.e., payment per action), a reduction in the number of required computations translates into significant cost savings. This understanding is also relevant to the field of malware detection, where organizations often deploy multiple types of detectors to increase detection accuracy. In this study, we utilize deep reinforcement learning to reduce computational costs in the cloud by selectively querying only a subset of available detectors. We demonstrate that our approach is not only effective both for on-premise and cloud-based computing architectures, but that applying it to serverless computing can reduce costs by an order of magnitude while maintaining near-optimal performance. © 2020 IEEE."
Federated Learning with Cooperating Devices: A Consensus Approach for Massive IoT Networks,"Federated learning (FL) is emerging as a new paradigm to train machine learning (ML) models in distributed systems. Rather than sharing and disclosing the training data set with the server, the model parameters (e.g., neural networks' weights and biases) are optimized collectively by large populations of interconnected devices, acting as local learners. FL can be applied to power-constrained Internet of Things (IoT) devices with slow and sporadic connections. In addition, it does not need data to be exported to third parties, preserving privacy. Despite these benefits, a main limit of existing approaches is the centralized optimization which relies on a server for aggregation and fusion of local parameters; this has the drawback of a single point of failure and scaling issues for increasing network size. This article proposes a fully distributed (or serverless) learning approach: the proposed FL algorithms leverage the cooperation of devices that perform data operations inside the network by iterating local computations and mutual interactions via consensus-based methods. The approach lays the groundwork for integration of FL within 5G and beyond networks characterized by decentralized connectivity and computing, with intelligence distributed over the end devices. The proposed methodology is verified by the experimental data sets collected inside an Industrial IoT (IIoT) environment. © 2014 IEEE."
Accelerated serverless computing based on GPU virtualization,"This paper introduces a platform to support serverless computing for scalable event-driven data processing that features a multi-level elasticity approach combined with virtualization of GPUs. The platform supports the execution of applications based on Docker containers in response to file uploads to a data storage in order to perform the data processing in parallel. This is managed by an elastic Kubernetes cluster whose size automatically grows and shrinks depending on the number of files to be processed. To accelerate the processing time of each file, several approaches involving virtualized access to GPUs, either locally or remote, have been evaluated. A use case that involves the inference based on deep learning techniques on transthoracic echocardiography imaging has been carried out to assess the benefits and limitations of the platform. The results indicate that the combination of serverless computing and GPU virtualization introduce an efficient and cost-effective event-driven accelerated computing approach that can be applied for a wide variety of scientific applications. © 2020 Elsevier Inc."
Polly: A Tool for Rapid Data Integration and Analysis in Support of Agricultural Research and Education,"Data analysis and modeling is a complex and demanding task. While a variety of software and tools exist to cope with this problem and tame big data operations, most of these tools are either not free, and when they are, they require large amount of configuration and steep learning curve. Moreover, they provide limited functionalities. In this paper we propose Polly, an online data analysis and modeling open-source tool that is intuitive to use and can be used with minimal or no configuration. Users can use Polly to rapidly integrate, analyze their data, prototype and test their novel methodologies. Polly can be used also as an educational tool. Users can use Polly to upload or connect to their structured data sources, load the required data into our system and perform various data processing tasks. Examples of such operations include data cleaning, data pre-processing, attribute encoding, regression and classification analysis. Aside from modeling, users can then download their results in the form of graphs in several standard visualization formats. While in this paper we focus on analyzing dataset for smart farming, our tool usage fits to a more general audience. To justify our backend design and implementation choices, we also present a performance analysis between backend virtualization technologies (containers or serverless computing), showing both expected and surprising results. © 2019 The Authors"
STOIC: Serverless Teleoperable Hybrid Cloud for Machine Learning Applications on Edge Device,"Serverless computing is a promising new event-driven programming model that was designed by cloud vendors to expedite the development and deployment of scalable web services on cloud computing systems. Using the model, developers write applications that consist of simple, independent, stateless functions that the cloud invokes on-demand (i.e. elastically), in response to system-wide events (data arrival, messages, web requests, etc.). In this work, we present STOIC (Serverless TeleOperable HybrId Cloud), an application scheduling and deployment system that extends the serverless model in two ways. First, it uses the model in a distributed setting and schedules application functions across multiple cloud systems. Second, STOIC supports serverless function execution using hardware acceleration (e.g. GPU resources) when available from the underlying cloud system. We overview the design and implementation of STOIC and empirically evaluate it using real-world machine learning applications and multi-tier (e.g. edge-cloud) deployments. We find that STOIC's combined use of edge and cloud resources is able to outperform using either cloud in isolation for the applications and datasets that we consider. © 2020 IEEE."
An Intelligent Doorbell Design Using Federated Deep Learning,"Smart doorbells have been playing an important role in protecting our modern homes. Existing approaches of sending video streams to a centralized server (or Cloud) for video analytics have been facing many challenges such as latency, bandwidth cost and more importantly users' privacy concerns. To address these challenges, this paper showcases the ability of an intelligent smart doorbell based on Federated Deep Learning, which can deploy and manage video analytics applications such as a smart doorbell across Edge and Cloud resources. This platform can scale, work with multiple devices, seamlessly manage online orchestration of the application components. The proposed framework is implemented using state-of-the-art technology. We implement the Federated Server using the Flask framework, containerized using Nginx and Gunicorn, which is deployed on AWS EC2 and AWS Serverless architecture. © 2021 Owner/Author."
Comparative study of real time machine learning models for stock prediction through streaming data,"Stock prediction is one of the emerging applications in the field of data science which help the companies to make better decision strategy. Machine learning models play a vital role in the field of prediction. In this paper, we have proposed various machine learning models which predicts the stock price from the real-time streaming data. Streaming data has been a potential source for real-time prediction which deals with continuous flow of data having information from various sources like social networking websites, server logs, mobile phone applications, trading floors etc. We have adopted the distributed platform, Spark to analyze the streaming data collected from two different sources as represented in two case studies in this paper. The first case study is based on stock prediction from the historical data collected from Google finance websites through NodeJs and the second one is based on the sentiment analysis of Twitter collected through Twitter API available in Stanford NLP package. Several researches have been made in developing models for stock prediction based on static data. In this work, an effort has been made to develop scalable, fault tolerant models for stock prediction from the real-time streaming data. The Proposed model is based on a distributed architecture known as Lambda architecture. The extensive comparison is made between actual and predicted output for different machine learning models.Support vector regression is found to have better accuracy as compared to other models. The historical data is considered as a ground truth data for validation. © 2020, IICM. All rights reserved."
Using cloud tools for literate programming to redesign an ai course for non-traditional college students,"As more open source educational software applications become available, higher educational institutions have the opportunity to utilize these cost efficient tools to deliver the instruction traditionally taught off line with heavy associated costs. Here we introduce a machine learning course that uses a simple, cloud computing approach to creating course materials. We see this type of serverless, cloud-based, literate programming to be the future of computer science education in non-traditional higher educational institutions in particular serving students who will need the basic literacy for computing and computation but will not pursue the traditional computer scientist path. © 2020, Association for the Advancement of Artificial Intelligence."
Contention-aware container placement strategy for docker swarm with machine learning based clustering algorithms,"Containerization technology utilizes operating system level virtualization to package applications to run with required libraries and are isolated from other processes on the same host. Lightweight and quick deployment make containers popular in many data centers. Running distributed applications in data centers usually involves multiple clusters of machines. Docker Swarm is a container orchestration tool for managing a cluster of Docker containers and their hosts. However, Docker Swarm’s scheduler does not consider resource utilization when placing containers in a cluster. This paper first investigated performance interference in container clusters. Our experimental study showed that distributed applications’ performance can be degraded when co-located with other containers which aggressively consume resources. A new scheduler is proposed to improve performance while keeping high resource utilization. The experimental results demonstrated that the proposed prototype with machine learning based clustering algorithms could effectively improve distributed applications’ performance by up to 14.5% with an average at around 12%. This work also provides theoretical bounds for the container placement problem. © 2020, Springer Science+Business Media, LLC, part of Springer Nature."
QoS-Aware Workload Distribution in Hierarchical Edge Clouds: A Reinforcement Learning Approach,"Recently, edge computing is getting attention as a new computing paradigm that is expected to achieve short-delay and high-throughput task offloading for large scale Internet-of-Things (IoT) applications. In edge computing, workload distribution is one of the most critical issues that largely influences the delay and throughput performance of edge clouds, especially in distributed Function-as-a-Service (FaaS) over networked edge nodes. In this paper, we propose the Resource Allocation Control Engine with Reinforcement learning (RACER), which provides an efficient workload distribution strategy to reduce the task response slowdown with per-task response time Quality-of-Service (QoS). First, we present a novel problem formulation with the per-task QoS constraint derived from the well-known token bucket mechanism. Second, we employ a problem relaxation to reduce the overall computation complexity by compromising just a bit of optimality. Lastly, we take the deep reinforcement learning approach as an alternative solution to the workload distribution problem to cope with the uncertainty and dynamicity of underlying environments. Evaluation results show that RACER achieves a significant improvement in terms of per-task QoS violation ratio, average slowdown, and control efficiency, compared to AREA, a state-of-the-art workload distribution method. © 2013 IEEE."
Real-time visualization of sensor data in smart manufacturing using lambda architecture,"Smart manufacturing technologies (Industry 4.0) as solutions to enhance productivity and improve efficiency are a priority to manufacturing industries worldwide. Such solutions have the ability to extract, integrate, analyze and visualize sensor and data from other legacy systems in order to enhance the operational performance. This paper proposes a solution to the challenge of real-time analysis and visualization of sensor and ERP data. Dynamic visualization is achieved using a machine learning approach. The combination of real-time visualization and machine learning allows for early detection and prevention of undesirable situations or outcomes. The prototype system has so far been tested by a smart manufacturing company with promising results. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved."
"HotCloud 2020 - 12th USENIX Workshop on Hot Topics in Cloud Computing, co-located with USENIX ATC 2020",The proceedings contain 22 papers. The topics discussed include: a cloud gaming framework for dynamic graphical rendering towards achieving distributed game engines; towards supporting millions of users in modifiable virtual environments by redesigning minecraft-like games as serverless systems; AI4DL: mining behaviors of deep learning workloads for resource management; Spotnik: designing distributed machine learning for transient cloud resources; model-switching: dealing with fluctuating workloads in machine-learning-as-a-service systems; towards GPU utilization prediction for cloud deep learning; serverless boom or bust? an analysis of economic incentives; no reservations: a first look at Amazon’s reserved instance marketplace; and auto-sizing for stream processing applications at LinkedIn.
FAASM: Lightweight isolation for efficient stateful serverless computing,"Serverless computing is an excellent fit for big data processing because it can scale quickly and cheaply to thousands of parallel functions. Existing serverless platforms isolate functions in ephemeral, stateless containers, preventing them from directly sharing memory. This forces users to duplicate and serialise data repeatedly, adding unnecessary performance and resource costs. We believe that a new lightweight isolation approach is needed, which supports sharing memory directly between functions and reduces resource overheads. We introduce Faaslets, a new isolation abstraction for high-performance serverless computing. Faaslets isolate the memory of executed functions using software-fault isolation (SFI), as provided by WebAssembly, while allowing memory regions to be shared between functions in the same address space. Faaslets can thus avoid expensive data movement when functions are co-located on the same machine. Our runtime for Faaslets, FAASM, isolates other resources, e.g. CPU and network, using standard Linux cgroups, and provides a low-level POSIX host interface for networking, file system access and dynamic loading. To reduce initialisation times, FAASM restores Faaslets from already-initialised snapshots. We compare FAASM to a standard container-based platform and show that, when training a machine learning model, it achieves a 2× speed-up with 10× less memory; for serving machine learning inference, FAASM doubles the throughput and reduces tail latency by 90%. Copyright © Proc. of the 2020 USENIX Annual Technical Conference, ATC 2020. All rights reserved."
CLOSER 2020 - Proceedings of the 10th International Conference on Cloud Computing and Services Science,The proceedings contain 52 papers. The topics discussed include: secure cloud storage with client-side encryption using a trusted execution environment; comparative evaluation of kernel bypass mechanisms for high-performance inter-container communications; a fuzzy controller for self-adaptive lightweight edge container orchestration; live migration timing optimization for VMware environments using machine learning techniques; bootstrapping and plug-and-play operations on software defined networks: a case study on self-configuration using the sonar architecture; fast analysis and prediction in large scale virtual machines resource utilization; enabling container cluster interoperability using a TOSCA orchestration framework; performance analysis of continuous binary data processing using distributed databases within stream processing environments; adaptive fog service placement for real-time topology changes in kubernetes clusters; and patterns for serverless functions (function-as-a-service): a multivocal literature review.
"Enabling Cost-Effective, SLO-Aware Machine Learning Inference Serving on Public Cloud","The remarkable advances of Machine Learning (ML) have spurred an increasing demand for ML-as-a-Service on publiccloud: developers train and publish ML models as online services to provide low-latency inference for dynamic queries. The primarychallenge of ML model serving is to meet the response-time Service-Level Objectives (SLOs) of inference workloads while minimizingserving cost. In this paper, we proposes MArk (Model Ark), a general-purpose inference serving system, to tackle the dual challenge ofSLO compliance and cost effectiveness. MArk employs three design choices tailored to inference workload. First, MArk dynamicallybatches requests and opportunistically serves them using expensive hardware accelerators (e.g., GPU) for improved performance-costratio. Second, instead of relying on feedback control scaling or over-provisioning to serve dynamic workload, which can be too slow ortoo expensive, MArk employs predictive autoscaling to hide the provisioning latency at low cost. Third, given the stateless nature ofinference serving, MArk exploits the flexible, yet costly serverless instances to cover occasional load spikes that are hard to predict. Weevaluated the performance of MArk using several state-of-the-art ML models trained in TensorFlow, MXNet, and Keras. Compared withthe premier industrial ML serving platform SageMaker, MArk reduces the serving cost up to 7.8while achieving even better latencyperformance. IEEE"
Optimizing serverless computing: Introducing an adaptive function placement algorithm,"The main concept behind serverless computing is to build and run applications without the need for server management. It refers to a fine-grained deployment model where applications, comprising of one or more functions, are uploaded to a platform and then executed, scaled, and billed in response to the exact demand needed at the moment. While elite cloud vendors such as Amazon, Google, Microsoft, and IBM are now providing serverless computing, their approach for the placement of functions, i.e. associated container or sandbox, on servers is oblivious to the workload which may lead to poor performance and/or higher operational cost for software owners. In this paper, using statistical machine learning, we design and evaluate an adaptive function placement algorithm which can be used by serverless computing platforms to optimize the performance of running functions while minimizing the operational cost. Given a fixed amount of resources, our smart spread function placement algorithm results in higher performance compared to existing approaches; this will be achieved by maintaining the users' desired quality of service for a longer time which prevents premature scaling of the cloud resources. Extensive experimental studies revealed that the proposed adaptive function placement algorithm can be easily adopted by serverless computing providers and integrated to container orchestration platforms without introducing any limiting side effects. © 2019 Copyright held by the owner/author(s)."
Towards the Use of Generative Adversarial Neural Networks to Attack Online Resources,"The role of remote resources, such as the ones provided by Cloud infrastructures, is of paramount importance for the implementation of cost effective, yet reliable software systems to provide services to third parties. Cost effectiveness is a direct consequence of a correct estimation of resource usage, to be able to define a budget and estimate the right price to put own services on the market. Attacks that overload resources with non legitimate requests, being them explicit attacks or just malicious, non harmful resource engagements, may push the use of Cloud resources beyond estimation, causing additional costs, or unexpected energy usage, or a lower overall quality of services, so intrusion detection devices or firewalls are set to avoid undesired accesses. We propose the use of Generative Adversarial Neural Networks (GANs) to setup a method for shaping request based attacks capable of reaching resources beyond defenses. The approach is studied by using a publicly available traffic data set, to test the concept and demonstrate its potential applications. © 2020, Springer Nature Switzerland AG."
A cloud-based framework for machine learning workloads and applications,"In this paper we propose a distributed architecture to provide machine learning practitioners with a set of tools and cloud services that cover the whole machine learning development cycle: ranging from the models creation, training, validation and testing to the models serving as a service, sharing and publication. In such respect, the DEEP-Hybrid-DataCloud framework allows transparent access to existing e-Infrastructures, effectively exploiting distributed resources for the most compute-intensive tasks coming from the machine learning development cycle. Moreover, it provides scientists with a set of Cloud-oriented services to make their models publicly available, by adopting a serverless architecture and a DevOps approach, allowing an easy share, publish and deploy of the developed models. © 2013 IEEE."
"10th International Conference on Computer Science and its Applications, CSA 2018 and the 13th KIPS International Conference on Ubiquitous Information Technologies and Applications, CUTE 2018",The proceedings contain 107 papers. The special focus in this conference is on Computer Science and its Applications. The topics include: QoE Unfairness in Dynamic Adaptive Streaming over HTTP; Interference-Aware Routing for Multi-hop Energy-Constrained Wireless Network with SWIPT; Developing Interactive Planning Methodology for EPC Projects; movie Recommendation System Using Social Network Analysis and k-Nearest Neighbor; a Framework for Learning the Pricing Model of Sensing Tasks in Crowdphotographing; tensor Decomposition Based Electrical Data Recovery; compressing Deep Neural Network; dynamic Projection Mapping Using Kinect-Based Skeleton Tracking; Parallel Bidirectional Shortest Path Computation in Graphs Using Relational Database Management Systems (RDBMSs); authoring Tool for Generating Multiple Experiences of 360° Virtual Reality; a Study of Open Big-Data Platform Architecture for Housing Market Analysis; resource-Aware Migration Scheme for QoS in Cloud Datacenter; A Dynamic FPGA Reconfiguration for Accelerating Machine Learning Framework with Image Service in OpenStack; Switchless Interconnect Network with PCIe Non-Transparent Bridge Interface; a Proposal of IoT Message-Oriented Service Framework for Serverless Software Architecture; deep Learning Based Gesture Recognition System for Immersive Broadcasting Production; mid-Level Feature Extractor for Transfer Learning to Small-Scale Dataset of Medical Images; design and Implementation of an Efficient Web Crawling Using Neural Network; An Intuitive VR Interaction Method for Immersive Virtual Reality; design and Implementation of a Partial Denoising Boundary Matching System Using Indexing Techniques; singing Lip Sync Animation System Using Audio Spectrum; a Tamper-Proof Digital Archiving Scheme Based on Blockchain; differential Data Processing for Energy Efficiency of Wireless Sensor Networks; implementation of Automatic Adjustment of Font Size System on Smartphone.
VideoPipe: Building video stream processing pipelines at the edge,"Real-time video processing in the home, with the benefits of low latency and strong privacy guarantees, enables virtual reality (VR) applications, augmented reality (AR) applications and other next-gen interactive applications. However, processing video feeds with computationally expensive machine learning algorithms may be impractical on a single device due to resource limitations. Fortunately, there are ubiquitous underutilized heterogeneous edge devices in the home. In this paper, we propose VideoPipe, a system that bridges the gap and runs flexible video processing pipelines on multiple devices. Towards this end, with inspirations from Function-as-a-Service (FaaS) architecture, we have unified the runtime environments of the edge devices. We do this by introducing modules, which are the basic units of a video processing pipeline and can be executed on any device. With the uniform design of input and output interfaces, we can easily connect any of the edge devices to form a video processing pipeline. Moreover, as some devices support containers, we further design and implement stateless services for more computationally expensive tasks such as object detection, pose detection and image classification. As they are stateless, they can be shared across pipelines and can be scaled easily if necessary. To evaluate the performance of our system, we design and implement a fitness application on three devices connected through Wi-Fi. We also implement a gesture-based Internet of Things (IoT) control application. Experimental results show the the promises of VideoPipe for efficient video analytics on the edge. © 2019 Association for Computing Machinery."
Highly flexible server agnostic complex event processing operators,"Complex Event Processing (CEP) is a powerful paradigm that can derive correlations from different data sources for a wide variety of applications. CEP provides semantic units called operators e.g., filter and join, that collectively represent a complex event. In current CEP systems, operators are highly dependent on the programming language and the underlying server. This restricts the capability of provisioning user-defined operators at runtime as well as the flexibility of developing server agnostic custom operators. In this paper, we provide a serverless CEP architecture, which offers developers the flexibility to design operators in any language and integrate them at runtime. We embed operators in the function as a service model of serverless architecture. This is very beneficial for applications such as financial fraud detection where complex machine learning operators must be integrated at runtime to avoid service disruption. We show using our preliminary evaluation that only with minimal overhead in latency, we can offer highly flexible server agnostic CEP operators. © 2019 Copyright held by the owner/author(s)."
On the FaaS track: Building stateful distributed applications with serverless architectures,"Serverless computing is an emerging paradigm that greatly simplifies the usage of cloud resources and suits well to many tasks. Most notably, Function-as-a-Service (FaaS) enables programmers to develop cloud applications as individual functions that can run and scale independently. Yet, due to the disaggregation of storage and compute resources in FaaS, applications that require fine-grained support for mutable state and synchronization, such as machine learning and scientific computing, are hard to build. In this work, we present Crucial, a system to program highly-concurrent stateful applications with serverless architectures. Its programming model keeps the simplicity of FaaS and allows to port effortlessly multi-threaded algorithms to this new environment. Crucial is built upon the key insight that FaaS resembles to concurrent programming at the scale of a data center. As a consequence, a distributed shared memory layer is the right answer to the need for fine-grained state management and coordination in serverless. We validate our system with the help of micro-benchmarks and various applications. In particular, we implement two common machine learning algorithms: k-means clustering and logistic regression. For both cases, Crucial obtains superior or comparable performance to an equivalent Spark cluster. © 2019 Association for Computing Machinery."
Monitorless: Predicting performance degradation in cloud applications with machine learning,"Today, software operation engineers rely on application key performance indicators (KPIs) for sizing and orchestrating cloud resources dynamically. KPIs are monitored to assess the achievable performance and to configure various cloud-specific parameters such as flavors of instances and autoscaling rules, among others. Usually, keeping KPIs within acceptable levels requires application expertise which is expensive and can slow down the continuous delivery of software. Expertise is required because KPIs are normally based on application-specific quality-of-service metrics, like service response time and processing rate, instead of generic platform metrics, like those typical across various environments (e.g., CPU and memory utilization, I/O rate, etc.) In this paper, we investigate the feasibility of outsourcing the management of application performance from developers to cloud operators. In the same way that the serverless paradigm allows the execution environment to be fully managed by a third party, we discuss a monitorless model to streamline application deployment by delegating performance management. We show that training a machine learning model with platform-level data, collected from the execution of representative containerized services, allows inferring application KPI degradation. This is an opportunity to simplify operations as engineers can rely solely on platform metrics – while still fulfilling application KPIs – to configure portable and application agnostic rules and other cloud-specific parameters to automatically trigger actions such as autoscaling, instance migration, network slicing, etc. Results show that monitorless infers KPI degradation with an accuracy of 97% and, notably, it performs similarly to typical autoscaling solutions, even when autoscaling rules are optimally tuned with knowledge of the expected workload. © 2019 Association for Computing Machinery."
Performance Characterization and Modeling of Serverless and HPC Streaming Applications,"Industrial and scientific streaming applications require support for different types of processing and the management of heterogeneous infrastructure over a dynamic range of scales: from the edge to the cloud and HPC, and intermediate resources. Serverless is an emerging service that combines high-level middleware services, such as distributed execution engines for managing tasks, with low-level infrastructure. It offers the potential of usability and scalability but adds to the complexity of managing heterogeneous and dynamic resources. In response, we extend Pilot-Streaming to support serverless platforms. Pilot-Streaming provides a unified abstraction for resource management for HPC, cloud, and serverless, and allocates resource containers independent of the application workload removing the need to write resource-specific code. Understanding the performance and scaling characteristics of streaming applications and infrastructure presents another challenge. StreamInsight provides insight into the performance of streaming applications and infrastructure, their selection, configuration, and scaling behavior. Underlying StreamInsight is the universal scalability law, which permits the accurate quantification of scalability properties of streaming applications. Using experiments on HPC and AWS Lambda, we demonstrate that StreamInsight provides an accurate model for a variety of application characteristics, e. g., machine learning model sizes and resource configurations. © 2019 IEEE."
Lifelong Machine Learning and root cause analysis for large-scale cancer patient data,"Introduction: This paper presents a lifelong learning framework which constantly adapts with changing data patterns over time through incremental learning approach. In many big data systems, iterative re-training high dimensional data from scratch is computationally infeasible since constant data stream ingestion on top of a historical data pool increases the training time exponentially. Therefore, the need arises on how to retain past learning and fast update the model incrementally based on the new data. Also, the current machine learning approaches do the model prediction without providing a comprehensive root cause analysis. To resolve these limitations, our framework lays foundations on an ensemble process between stream data with historical batch data for an incremental lifelong learning (LML) model. Case description: A cancer patient’s pathological tests like blood, DNA, urine or tissue analysis provide a unique signature based on the DNA combinations. Our analysis allows personalized and targeted medications and achieves a therapeutic response. Model is evaluated through data from The National Cancer Institute’s Genomic Data Commons unified data repository. The aim is to prescribe personalized medicine based on the thousands of genotype and phenotype parameters for each patient. Discussion and evaluation: The model uses a dimension reduction method to reduce training time at an online sliding window setting. We identify the Gleason score as a determining factor for cancer possibility and substantiate our claim through Lilliefors and Kolmogorov–Smirnov test. We present clustering and Random Decision Forest results. The model’s prediction accuracy is compared with standard machine learning algorithms for numeric and categorical fields. Conclusion: We propose an ensemble framework of stream and batch data for incremental lifelong learning. The framework successively applies first streaming clustering technique and then Random Decision Forest Regressor/Classifier to isolate anomalous patient data and provides reasoning through root cause analysis by feature correlations with an aim to improve the overall survival rate. While the stream clustering technique creates groups of patient profiles, RDF further drills down into each group for comparison and reasoning for useful actionable insights. The proposed MALA architecture retains the past learned knowledge and transfer to future learning and iteratively becomes more knowledgeable over time. © 2019, The Author(s)."
Modified deep residual network architecture deployed on serverless framework of IoT platform based on human activity recognition application,"In the last few years, human activity recognition (HAR) is a subject undergoing intense study in various contexts such as pattern recognition and human-device interaction. HAR applications come to an aid of Telecare system which is paving the way for doctors and nurses to measure the health status of their patients. Due to the ubiquitous influence of smartphones in an individual's life, we take embedded smartphone sensors into account as our case study. The proposed method, Modified Deep Residual Network, outperforms the accuracy of Human activity recognition compared with state-of-the-art machine learning techniques which are using Raw signals as their input. we defined new pooling layer called smooth-pooling to leverage the model performance. The accuracy of proposed architecture is evaluated on three common dataset that comprises accelerometer and gyroscope raw data. The results demonstrated the proposed method outperforms accuracy of classification while requiring just raw data with lower parameters compared to other works. Furthermore, The proposed HAR method is deployed in our IoT cloud platform which enables users to create scenarios based on what they are doing at home. Using Function as a Service (FaaS) architecture in this platform solves the scalability issues by running each function in a separate container. The IoT platform prepares an infrastructure for developers who want to integrate their application into the platform and use its functionality along with other IoT platform options. © 2019 Elsevier B.V."
"Big Data Processing at Microsoft: Hyper Scale, Massive Complexity, and Minimal Cost","The past decade has seen a tremendous interest in large-scale data processing at Microsoft. Typical scenarios include building business-critical pipelines such as advertiser feedback loop, index builder, and relevance/ranking algorithms for Bing; analyzing user experience telemetry for Office, Windows or Xbox; and gathering recommendations for products like Windows and Xbox. To address these needs a first-party big data analytics platform, referred to as Cosmos, was developed in the early 2010s at Microsoft. Cosmos makes it possible to store data at exabyte scale and process in a serverless form factor, with SCOPE [4] being the query processing workhorse. Over time, however, several newer challenges have emerged, requiring major technical innovations in Cosmos to meet these newer demands. In this abstract, we describe three such challenges from the query processing viewpoint, and our approaches to handling them. Hyper Scale. Cosmos has witnessed a significant growth in usage from its early days, from the number of customers (starting from Bing to almost every single business unit at Microsoft today), to the volume of data processed (from petabytes to exabytes today), to the amount of processing done (from tens of thousands of SCOPE jobs to hundreds of thousands of jobs today, across hundreds of thousands of machines). Even a single job can consume tens of petabytes of data and produce similar volumes of data by running millions of tasks in parallel. Our approach to handle this unprecedented scale is two fold. First, we decoupled and disaggregated the query processor from storage and resource management components, thereby allowing different components in the Cosmos stack to scale independently. Second, we scaled the data movement in the SCOPE query processor with quasilinear complexity [2]. This is crucial since data movement is often the most expensive step, and hence the bottleneck, in massive-scale data processing. Massive Complexity. Cosmos workloads are also highly complex. Thanks to adoption across the whole of Microsoft, Cosmos needs to support workloads that are representative of multiple industry segments, including search engine (Bing), operating system (Windows), workplace productivity (Office), personal computing (Surface), gaming (XBox), etc. To handle such diverse workloads, our approach has been to provide a one-size-fits-All experience. First of all, to make it easy for the customers to express their computations, SCOPE supports different types of queries, from batch to interactive to streaming and machine learning. Second, SCOPE supports both structured and unstructured data processing. Likewise, multiple data formats, including both propriety and open source source such as Parquet, are supported. Third, users can write business logic using a mix of declarative and imperative languages, over even different imperative languages such as C# and Python, in the same job. Furthermore, users can express all of the above in simple data flow style computation for better readability and maintainability. Finally, considering the diverse workload mix inside Microsoft, we have come to realization that it is not possible to fits all scenarios using SCOPE. Therefore, we also support the popular Spark query processing engine. Overall, the one-size-fits-All query processing experience in Cosmos covers very diverse workloads, including data formats, programming languages, and the backend engines. Minimal Cost. While scale and complexity are hard by themselves, the biggest challenge is to achieve all of that at minimal cost. In fact, there is a pressing need to improve Cosmos efficiency and reduce operational costs. This is challenging due to several reasons. First, optimizing a SCOPE job is hard considering that the SCOPE DAGs are super large (up to 1000s of operators in single job!), and the optimization estimates (cardinality, cost, etc.) are often way off from the actuals. Second, SCOPE optimizes a given query, while the operational costs depend on the overall workload. Therefore workload optimization becomes very important. And finally, SCOPE jobs are typically interlinked in data pipelines, i.e., the output of one job is consumed by other jobs. This means that workload optimization needs to be aware of these dependencies. Our approach is to develop a feedback loop to learn from past workloads in order to optimize the future ones. Specifically, we leverage machine learning to learn models for optimizing individual jobs [3], apply multi-query optimizations to optimize the costs of overall workload [1], and build dependency graphs to identify and optimize for the data pipelines. © 2019 Owner/Author."
Cirrus: A Serverless Framework for End-To-end ML Workflows,"Machine learning (ML) workflows are extremely complex. The typical workflow consists of distinct stages of user interaction, such as preprocessing, training, and tuning, that are repeatedly executed by users but have heterogeneous computational requirements. This complexity makes it challenging for ML users to correctly provision and manage resources and, in practice, constitutes a significant burden that frequently causes over-provisioning and impairs user productivity. Serverless computing is a compelling model to address the resource management problem, in general, but there are numerous challenges to adopt it for existing ML frameworks due to significant restrictions on local resources. This work proposes Cirrus-An ML framework that automates the end-To-end management of datacenter resources for ML workflows by efficiently taking advantage of serverless infrastructures. Cirrus combines the simplicity of the serverless interface and the scalability of the serverless infrastructure (AWS Lambdas and S3) to minimize user effort. We show a design specialized for both serverless computation and iterative ML training is needed for robust and efficient ML training on serverless infrastructure. Our evaluation shows that Cirrus outperforms frameworks specialized along a single dimension: Cirrus is 100x faster than a general purpose serverless system [36] and 3.75x faster than specialized ML frameworks for traditional infrastructures [49]. © 2019 ACM."
Serving machine learning workloads in resource constrained environments: A serverless deployment example,"Deployed AI platforms typically ship with bulky system architectures which present bottlenecks and a high risk of failure. A serverless deployment can mitigate these factors and provide a cost-effective, automatically scalable (up or down) and elastic real-time on-demand AI solution. However, deploying high complexity production workloads into serverless environments is far from trivial, e.g., due to factors such as minimal allowance for physical codebase size, low amount of runtime memory, lack of GPU support and a maximum runtime before termination via timeout. In this paper we propose a set of optimization techniques and show how these transform a codebase which was previously incompatible with a serverless deployment into one that can be successfully deployed in a serverless environment; without compromising capability or performance. The techniques are illustrated via worked examples that have been deployed live on rail data and realtime predictions on train movements on the UK rail network. The similarities of a serverless environment to other resource constrained environments (IoT, Mobile) means the techniques can be applied to a range of use cases. © 2019 IEEE."
NetflowTotal: A cloud service integration platform for malicious traffic analysis and collaboration,"Network security lacks the verification of real world net flow data, and lacks a platform to collect and integrate net flow data and threat intelligence, so as to generate an evaluation benchmark for machine learning on cybersecurity. NetFlowTotal develop many net flow analysis tools to detect malicious threats in the net flow data. Through the two-side market strategies, NetFlowTotal platform tie together two distinct groups of users in a network. One kind of user can upload net flow data to the NetFlowTotal platform to obtain security incidents reports; the other kind of user can share threat intelligence to the NetFlowTotal platform to obtain more associate threat intelligence according to global net flow data. The goal of this paper is to establish a net flow evaluation platform to provide real world dataset with security incidents reports for machine learning evaluation. © 2019 Association for Computing Machinery."
"Bighead: A framework-agnostic, end-to-end machine learning platform","With the increasing need to build systems and products powered by machine learning inside organizations, it is critical to have a platform that provides machine learning practitioners with a unified environment to easily prototype, deploy, and maintain their models at scale. However, due to the diversity of machine learning libraries, the inconsistency between environments, and various scalability requirement, there is no existing work to date that addresses all of these challenges. Here, we introduce Bighead, a framework-agnostic, end-to-end platform for machine learning. It offers a seamless user experience requiring only minimal efforts that span feature set management, prototyping, training, batch (offline) inference, real-time (online) inference, evaluation, and model lifecycle management. In contrast to existing platforms, it is designed to be highly versatile and extensible, and supports all major machine learning frameworks, rather than focusing on one particular framework. It ensures consistency across different environments and stages of the model lifecycle, as well as across data sources and transformations. It scales horizontally and elastically in response to the workload such as dataset size and throughput. Its components include a feature management framework, a model development toolkit, a lifecycle management service with UI, an offline training and inference engine, an online inference service, an interactive prototyping environment, and a Docker image customization tool. It is the first platform to offer a feature management component that is a general-purpose aggregation framework with lambda architecture and temporal joins. Bighead is deployed and widely adopted at Airbnb, and has enabled the data science and engineering teams to develop and deploy machine learning models in a timely and reliable manner. Bighead has shortened the time to deploy a new model from months to days, ensured the stability of the models in production, facilitated adoption of cutting-edge models, and enabled advanced machine learning based product features of the Airbnb platform. We present two use cases of productionizing models of computer vision and natural language processing. © 2019 IEEE."
Short paper: Tigeraware assistant: A new serverless implementation of conversational agents for customizable surveys on smart devices,"Applications of conversational agents, also called chatbots, have accelerated in recent years. However, it is difficult for people with limited programming skills to implement chatbots and analyze the data collected by chatbots. In this paper, we present a new serverless implementation of conversational agents for delivering customizable surveys on smart devices, including smartphones and smart speakers, and a web-based system for applying advanced analytics techniques to survey data using cloud services. The system is called TigerAware Assistant, as part of the TigerAware platform for customizable mobile survey and sensor data collection. TigerAware Assistant enables non-technical people to easily create and deploy chatbots on various mobile devices to conduct surveys through conversations in natural languages via auditory and textual methods. It also provides a web-based system for survey data visualization, statistical analysis, and advanced machine learning-based data analysis using cloud services on survey responses collected by chatbots. © 2019 IEEE."
Real-Time Estimated Time of Arrival Prediction System using Historical Surveillance Data,"Prediction of Estimated Times of Arrival (ETA) is a challenging problem for the aviation industry. Flights recurrently deviate from their scheduled time of arrival, which has negative downstream consequences that affect the efficiency of operations. Therefore, accurate and up-to-date ETA estimations prior to its landing can help in optimizing the actions to be taken by the different air transportation agents whenever schedule deviations are incurred, and thus reduce the economic, logistic and environmental impact that they cause. This presentation exposes an infrastructure for high-fidelity computation of accurate ETA in real-time, based on a data-driven approach that leverages the use of recorded aircraft trajectories. This infrastructure is composed of different elements: (1) a live ADS-B tracks gathering system embedded in a lambda-architecture cluster, with capabilities for real-time distribution and data lake storage (2) an ETA prediction machine learning model, employing the actual 4D aircraft position as input; and (3) a hybrid cloud architecture to support real-time visualization and distributions of ETA predictions. The proposed infrastructure has been successfully validated in a real environment (Transforming Transport, an European Commission funded project). This infrastructure enables real-time computation and distribution of accurate ETA for any arrival operation of interest. Results supported the envisioned benefits of getting such accurate ETA, which basically turn into a reduction of associated costs for airport authorities and airlines. © 2019 IEEE."
AssistantGraph: An approach for reusable and composable data-driven assistant components,"Steady progress in ubiquitous technologies and machine learning facilitates ever-new and better digital assistants. However, most of these emerging assistants rely on-partly similar-data-driven analyses that are independent of each other, leading to redundancy issues. In this paper, we propose a novel concept (termed AssistantGraph) for an efficient design and runtime support of digital assistants. More specifically, assistants need to represent their data-driven processing pipelines as a directed acyclic graph of assistant components (modularity) to benefit from serverless computing with data access. Facilitated component sharing across assistants (reusability) leads to a more connected and efficient overall graph: a shared component instance requires to run only once; versioned components are enabled by the proposed backward chains of converters (versioning). We further develop data and control flow mechanisms through recursive filtering on demand to trigger the data-driven components as required. Within a novel proposed and prototypically implemented open assistant infrastructure, we evaluate our concept in terms of feasibility and performance. The results show reduced redundancy with simultaneous significant performance gains (through component sharing) despite minimal additional overhead (due to modularization and backward compatibility). We believe that our approach gives a new perspective on data-driven assistants and complements an open assistant ecosystem. © 2019 IEEE."
"Proceedings - 2019 IEEE International Conference on Cloud Computing, CLOUD 2019 - Part of the 2019 IEEE World Congress on Services",The proceedings contain 84 papers. The topics discussed include: data protection as a service in the multi-cloud environment; robust management of trans-cloud applications; an adaptive approach for dealing with flow disruption in virtualized water-cooled data centers; cloud VM provisioning using analytical performance models; QuADD : quantifying accelerator disaggregated datacenter efficiency; TrIMS: transparent and isolated model sharing for low latency deep learning inference in function-as-a-service; STRETCH: in-memory storage with autoscaling for cluster computing; exploiting serverless runtimes for large-scale optimization; and non-intrusive cloud application transaction pattern discovery.
TrIMS: Transparent and isolated model sharing for low latency deep learning inference in function-as-a-service,"Deep neural networks (DNNs) have become core computation components within low latency Function as a Service (FaaS) prediction pipelines. Cloud computing, as the defacto backbone of modern computing infrastructure, has to be able to handle user-defined FaaS pipelines containing diverse DNN inference workloads while maintaining isolation and latency guarantees with minimal resource waste. The current solution for guaranteeing isolation and latency within FaaS is inefficient. A major cause of the inefficiency is the need to move large amount of data within and across servers. We propose TrIMS as a novel solution to address this issue. TrIMSis a generic memory sharing technique that enables constant data to be shared across processes or containers while still maintaining isolation between users. TrIMS consists of a persistent model store across the GPU, CPU, local storage, and cloud storage hierarchy, an efficient resource management layer that provides isolation, and a succinct set of abstracts, applicationAPIs, and container technologies for easy and transparent integration with FaaS, Deep Learning (DL) frameworks, and user code. We demonstrate our solution by interfacing TrIMS with the Apache MXNet framework and demonstrate up to 24x speedup in latency for image classification models, up to 210x speedup for large models, and up to8×system throughput improvement. © 2019 IEEE."
Seneca: Fast and low cost hyperparameter search for machine learning models,"The goal of our work is to simplify and expedite the construction and evaluation of machine learning models using autoscaled cloud computing resources. To enable this, we develop an open source system called Seneca, which leverages the serverless programming model and its implementation in Amazon Web Services (AWS) Lambda. Seneca takes a machine learning application, dataset, and a list of possible hyperparameter options as input and automatically constructs an AWS Lambda function. The function ingresses and splits the input dataset into training and testing subsets and constructs, tests, and evaluates (i.e. scores) a machine learning model for a given set of hyperparameter values. Seneca concurrently invokes functions for all combinations of the hyperparameters specified. It then returns the configuration (or model) that results in the best score to the user. In this paper, we overview the design and implementation of Seneca, and empirically evaluate its performance for a popular classification application. © 2019 IEEE."
"Sharing learnings: The methodology, optimisation and benefits of moving subsurface data to the public cloud","We detail the application of cloud technology to Chevron's seismic data repository, share the applicable learnings and highlight areas of workflow evolution that delivered value. The aim of the project, run as a piloted field trial, was to couple the transformative capability of public cloud services with subsurface data. The learnings shared in this paper are designed to inform and assist other subsurface data custodians whether they are energy companies, national data repositories, service companies or academia. Cloud technology enables us to reduce seismic data duplication to a single data version which can be accessed securely by all appropriate stakeholders. We discuss a highly automated, scalable data migration process which included seismic ingestion, machine learning and serverless architecture. This automated the data management process, progressing data from loading to global analysis in minutes. The project has provided access to subsurface data anytime, anywhere and on any device, delivering a more accessible data environment at lower costs and connecting via an API to traditional workflows. By approaching the subsurface data challenge in an innovative way, this project has provided multiple learnings to share and built a greater understanding of the value case for faster adoption of public cloud infrastructure. © 81st EAGE Conference and Exhibition 2019. All rights reserved."
BARISTA: Efficient and scalable serverless serving system for deep learning prediction services,"Pre-trained deep learning models are increasingly being used to offer a variety of compute-intensive predictive analytics services such as fitness tracking, speech, and image recognition. The stateless and highly parallelizable nature of deep learning models makes them well-suited for serverless computing paradigm. However, making effective resource management decisions for these services is a hard problem due to the dynamic workloads and diverse set of available resource configurations that have different deployment and management costs. To address these challenges, we present a distributed and scalable deep-learning prediction serving system called Barista and make the following contributions. First, we present a fast and effective methodology for forecasting workloads by identifying various trends. Second, we formulate an optimization problem to minimize the total cost incurred while ensuring bounded prediction latency with reasonable accuracy. Third, we propose an efficient heuristic to identify suitable compute resource configurations. Fourth, we propose an intelligent agent to allocate and manage the compute resources by horizontal and vertical scaling to maintain the required prediction latency. Finally, using representative real-world workloads for an urban transportation service, we demonstrate and validate the capabilities of Barista. © 2019 IEEE."
A Recurrent Neural Network Based Approach for Web Service QoS Prediction,"QoS (Quality of Service) is a series of widely used indicators for networked user-oriented online services such as SOAP/JSON based web services, serverless microservices or function services in the modern cloud market. Of which, response time and throughput are most important measurements which almost determine the whole user experience caused by underlying factors including network delay or congestion, fluctuating service computation performance at different system workload level, or constrained by cascading resource or service dependencies. It's valuable to accurately predict QoS indicators under complex scenarios and conditions combination from archived history service experience dataset. In this paper, two subsets of real-world dataset named WS-DREAM were used, which collected 339 users' records on 5825 web services. Based on related work and descriptive analysis, two QoS (response time and throughput) prediction models were proposed for classification and regression problems. A custom recurrent neural network(RNN) was proposed, which comprises stacked multiple LSTM(Long term and Short Term Memory) layers, several regularization techniques were used. Extensive experiments were conducted to verify the accuracy and efficiency of deep learning based approach comparing with 6 competitive machine learning approaches, including decision tree, AdaBoost, multilayer perceptron, XGBoost, LightGBM, and CatBoost. Results showed the prediction accuracy of most algorithms could reach more than 90%, and the proposed RNN based network showed a superior performance both at accuracy and efficiency than other approaches. © 2019 IEEE."
Serverless data parallelization for training and retraining of deep learning architecture in patient-specific arrhythmia detection,"Stacked Denoising Autoencoders (SDA) are deep networks which have superior generative properties and therefore can be trained and retrained to learn the structure of a patient's heart beat signal with minimal training data. This approach is particularly useful in continuous remote devices because they gather large amounts of data for longer periods of time. Serverless applications are the desired way of building applications due to its cost effectiveness after advancements in commercially available serverless host providers like Amazon AWS. This work proposes a serverless architecture for the training and retraining of SDA, for classification of arrhythmias in a patient-specific manner. This work also proposes a technique for data parallelization in the serverless architecture to achieve a speedup of up-To 13x in training time. This work uses MIT-BIH Arrhythmia database. Retraining with this architecture shows high classification accuracies for Ventricular Ectopic Beats (VEB) (97.41%) and Supraventricular Ectopic Beats (SVEB) (98.77%). © 2019 IEEE."
"Proceedings - 2019 IEEE 33rd International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2019","The proceedings contain 112 papers. The topics discussed include: an accurate tool for modeling, fingerprinting, comparison, and clustering of parallel applications based on performance counters; SmarTmem: intelligent management of transcendent memory in a virtualized server; data reliability and redundancy optimization of a secure multi-cloud storage under uncertainty of errors and falsifications; a portable GPU framework for SNP comparisons; towards a methodology for benchmarking edge processing frameworks; a fast local algorithm for track reconstruction on parallel architectures; towards native execution of deep learning on a leadership-class hpc system; improving robustness of heterogeneous serverless computing systems via probabilistic task pruning; and influence of tasks duration variability on task-based runtime schedulers."
Distributed Machine Learning with a Serverless Architecture,"The need to scale up machine learning, in the presence of a rapid growth of data both in volume and in variety, has sparked broad interests to develop distributed machine learning systems, typically based on parameter servers. However, since these systems are based on a dedicated cluster of physical or virtual machines, they have posed non-trivial cluster management overhead to machine learning practitioners and data scientists. In addition, there exists an inherent mismatch between the dynamically varying resource demands during a model training job and the inflexible resource provisioning model of current cluster-based systems.In this paper, we propose SIREN, an asynchronous distributed machine learning framework based on the emerging serverless architecture, with which stateless functions can be executed in the cloud without the complexity of building and maintaining virtual machine infrastructures. With SIREN, we are able to achieve a higher level of parallelism and elasticity by using a swarm of stateless functions, each working on a different batch of data, while greatly reducing system configuration overhead. Furthermore, we propose a scheduler based on Deep Reinforcement Learning to dynamically control the number and memory size of the stateless functions that should be used in each training epoch. The scheduler learns from the training process itself, in pursuit for the minimum possible training time given a cost. With our real-world prototype implementation on AWS Lambda, extensive experimental results have shown that SIREN can reduce model training time by up to 44%, as compared to traditional machine learning training benchmarks on AWS EC2 at the same cost. © 2019 IEEE."
Behavior analysis using serverless machine learning,"This paper supplies a route for using the Watson Machine Learning API on IBM Cloud to carry out serverless data analytics using machine learning as a service. Transforming the large amount of data produced by an organization into intelligence can be done using advanced analytics methods such as using a modified Mahalanobis Distance algorithm for synthesis of correlation data under the purview of machine learning. Further refinement of correlation data is done using a Multivariate Reliability Classifier model. The consumption of this advanced analytics service can be done in a serverless manner where the developer only must be concerned with how the data is analyzed, i.e., scoring, batch or stream models with a continuous learning system without the outlay of hardware upon which to train those models. This paper examines the usage of such serverless AI systems in the scope of user behavior analysis over varied demographics. © 2019 Bharati Vidyapeeth, New Delhi. Copy Right in Bulk will be transferred to IEEE by Bharati Vidyapeeth."
AI on the Move: From On-Device to On-Multi-Device,"On-Device AI is an emerging paradigm that aims to make devices more intelligent, autonomous and proactive by equipping them with machine and deep learning routines for robust decision making and optimal execution in devices' operations. On-Device intelligence promises the possibility of computing huge amounts of data close to its source, e.g., sensor and multimedia data. By doing so, devices can complement their counterpart cloud services with more sophisticated functionality to provide better applications and services. However, increased computational capabilities of smart devices, wearables and IoT devices along with the emergence of services at the Edge of the network are driving the trend of migrating and distributing computation between devices. Indeed, devices can reduce the burden of executing resource intensive tasks via collaborations in the wild. While several work has shown the benefits of an opportunistic collaboration of a device with others, not much is known regarding how devices can be organized as a group as they move together. In this paper, we contribute by analyzing how dynamic group organization of devices can be utilized to distribute intelligence on the moving Edge. The key insight is that instead of On-Device solutions complementing with cloud, dynamic groups can be formed to complement each other in an On-Multi-Device manner. Thus, we highlight the challenges and opportunities from extending the scope of On-Device AI from an egocentric view to a collaborative, multi-device view. © 2019 IEEE."
The next generation cognitive security operations center: Adaptive analytic lambda architecture for efficient defense against adversarial attacks,"A Security Operations Center (SOC) is a central technical level unit responsible for monitoring, analyzing, assessing, and defending an organization’s security posture on an ongoing basis. The SOC staff works closely with incident response teams, security analysts, network engineers and organization managers using sophisticated data processing technologies such as security analytics, threat intelligence, and asset criticality to ensure security issues are detected, analyzed and finally addressed quickly. Those techniques are part of a reactive security strategy because they rely on the human factor, experience and the judgment of security experts, using supplementary technology to evaluate the risk impact and minimize the attack surface. This study suggests an active security strategy that adopts a vigorous method including ingenuity, data analysis, processing and decision-making support to face various cyber hazards. Specifically, the paper introduces a novel intelligence driven cognitive computing SOC that is based exclusively on progressive fully automatic procedures. The proposed λ-Architecture Network Flow Forensics Framework (λ-NF3) is an efficient cybersecurity defense framework against adversarial attacks. It implements the Lambda machine learning architecture that can analyze a mixture of batch and streaming data, using two accurate novel computational intelligence algorithms. Specifically, it uses an Extreme Learning Machine neural network with Gaussian Radial Basis Function kernel (ELM/GRBFk) for the batch data analysis and a Self-Adjusting Memory k-Nearest Neighbors classifier (SAM/k-NN) to examine patterns from real-time streams. It is a forensics tool for big data that can enhance the automate defense strategies of SOCs to effectively respond to the threats their environments face. © 2019 by the authors. Licensee MDPI, Basel, Switzerland."
Big Data Ingestion and Lifelong Learning Architecture,"Lifelong Machine Learning (LML) mimics common human learning experiences. Humans undergo through long learning phase at start while studying followed by updating knowledge base incrementally from everyday instances. The objective is to retain past learnt knowledge and transfer learning to the next task iteratively. Training on the large data pool through a one-shot long running batch job limits the responsiveness and increases the infrastructure cost through large cluster requirements. The full dataset may not be available as well at the initiation of the training process. Through a review of previous work on lifelong machine leaning, we propose a Multi-agent Lambda Architecture (MALA) model to combine historical batch data with live streaming data to develop a lifelong learning system. MALA allows the streaming process to initialize itself with trained model from the batch data. Streaming process takes the batch data offset and incrementally updates the model iteratively with new waves of data. Reasons for our claim are presented through implementation of a recommender engine. © 2018 IEEE."
A Unified Framework for 5G Network Management Tools,"Limitations in the software architecture of current network management tools such as lack of support for combined batch and real time data processing, adaptive machine learning, support for heterogeneous data sources and the fragmentation of emerging solutions needs to be addressed in order to create a solid and forward leaning foundation for implementing 5G solutions. To address these limitations, this paper introduces the extended lambda architecture (ELA). It focuses on bringing agility and continuous learning based decision making support into the design of a unified architectural framework for new network management tools by combining batch and real time data processing with adaptive machine learning in a simple Monitor-Analyze-Plan-Execute over a shared Knowledge (MAPE-K) loop. The benefits of using this architecture are evaluated using a proof of concept (PoC) implementation of a reliable and proactive tool for detection and compensation of cell outages in a simulated 5G network. © 2018 IEEE."
Azure internet of things revealed: Architecture and fundamentals,"Introduction Design, build, and justify an optimal Microsoft IoT footprint to meet your project needs. This book describes common Internet of Things components and architecture and then focuses on Microsoft’s Azure components relevant in deploying these solutions. Microsoft-specific topics addressed include: deploying edge devices and pushing intelligence to the edge; connecting IoT devices to Azure and landing data there, applying Azure Machine Learning, analytics, and Cognitive Services; roles for Microsoft solution accelerators and managed solutions; and integration of the Azure footprint with legacy infrastructure. The book concludes with a discussion of best practices in defining and developing solutions and creating a plan for success. You will: Design the right IoT architecture to deliver solutions for a variety of project needs Connect IoT devices to Azure for data collection and delivery of services Use Azure Machine Learning and Cognitive Services to deliver intelligence in cloud-based solutions and at the edge Understand the benefits and tradeoffs of Microsoft’s solution accelerators and managed solutions Investigate new use cases that are described and apply best practices in deployment strategies Integrate cutting-edge Azure deployments with existing legacy data sources. © 2019 by Robert Stackowiak."
"Mark: Exploiting cloud services for cost-effective, slo-aware machine learning inference serving","The advances of Machine Learning (ML) have sparked a growing demand of ML-as-a-Service: developers train ML models and publish them in the cloud as online services to provide low-latency inference at scale. The key challenge of ML model serving is to meet the response-time Service-Level Objectives (SLOs) of inference workloads while minimizing the serving cost. In this paper, we tackle the dual challenge of SLO compliance and cost effectiveness with MArk (Model Ark), a general-purpose inference serving system built in Amazon Web Services (AWS). MArk employs three design choices tailor-made for inference workload. First, MArk dynamically batches requests and opportunistically serves them using expensive hardware accelerators (e.g., GPU) for improved performance-cost ratio. Second, instead of relying on feedback control scaling or over-provisioning to serve dynamic workload, which can be too slow or too expensive for inference serving, MArk employs predictive autoscaling to hide the provisioning latency at low cost. Third, given the stateless nature of inference serving, MArk exploits the flexible, yet costly serverless instances to cover the occasional load spikes that are hard to predict. We evaluated the performance of MArk using several state-of-the-art ML models trained in popular frameworks including TensorFlow, MXNet, and Keras. Compared with the premier industrial ML serving platform SageMaker, MArk reduces the serving cost up to 7.8× while achieving even better latency performance. © Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019. All rights reserved."
The Changing Role of the Software Engineer,"In this paper we will discuss the changing role of a software engineer. We will examine this from four major standpoints, the software development lifecycle, the influence of open source software, testing and deployment and the emergence of new technologies. We will first analyze what the role of a software engineer was in the past. We will examine limitations associated with software development life cycle models, and software failures that catalyzed increased importance for quality assurance. We then outline the current role of a software engineer. We discuss the impact of agile software development and automation on the software development cycle, the influence of open source software and how new technologies such as Function-as-a-Service and machine learning may impacted the role. Based on our research, we analyze why the software engineer role has changed and postulate prospective changes to the role of software engineer, and in particular how new responsibilities may affect the day to day work of future software engineers. We ultimately find that the role of a “software engineer” is nowadays widely varied and very broad, and it only generally indicates the type of work that the software engineer may undertake. © Springer Nature Switzerland AG 2019."
Stratum: A serverless framework for the lifecycle management of machine learning-based data analytics tasks,"With the proliferation of machine learning (ML) libraries and frameworks, and the programming languages that they use, along with operations of data loading, transformation, preparation and mining, ML model development is becoming a daunting task. Furthermore, with a plethora of cloud-based ML model development platforms, heterogeneity in hardware, increased focus on exploiting edge computing resources for low-latency prediction serving and often a lack of a complete understanding of resources required to execute ML workflows efficiently, ML model deployment demands expertise for managing the lifecycle of ML workflows efficiently and with minimal cost. To address these challenges, we propose an end-to-end data analytics, a serverless platform called Stratum. Stratum can deploy, schedule and dynamically manage data ingestion tools, live streaming apps, batch analytics tools, ML-as-a-service (for inference jobs), and visualization tools across the cloud-fog-edge spectrum. This paper describes the Stratum architecture highlighting the problems it resolves."
MPC with machine learning applied to resource allocation problem using lambda architecture,"The resource allocation problem is the process of allocating limited resources for a vast amount of tasks. Within this problem there are several important variants such as the stochastic time-variant resource allocation problem. This problem is relevant within environments where the distribution of resources varies with time, bringing difficulties to forecasting. Related research generally address the problem by using model predictive control (MPC) techniques or machine learning (ML) algorithms. However, both can be applied together in order to improve the tasks prioritization and forecasting. Therefore, this paper proposes a solution using the concept of lambda architecture in order to tackle the time-variant and the distinct input information. First results show that the integration between MPC and ML prioritizes the resource allocation and a Markov chain model is capable of forecasting tasks, optimizing a strategic binary control. We analyze a case study of a real problem and show how the proposal was built and its advantages over the traditional method. © 2019, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved."
Big-data architecture for electrical consumption forecasting in educational institutions buildings,"Recently, educational institutions suffer from high electrical consumption due to their new practices and activities. One of the promising solutions to overcome this challenge is to improve their energy management strategies using smart grids which ensure efficiency, reliability and energy saving. For this same reason, the National School of Applied Sciences of El Jadida - Morocco has decided to install a private smart grid based on photovoltaic panels that will cover 40% of its electricity needs. But the problem that arises when using this new approach is the high level of complexity in term of data management due to the variety, veracity and the volume of the data. So, to meet these needs the use of Big Data technologies is required. In this paper, we propose a Big Data solution based on Lambda architecture to handle electrical consumption data in the National School of Applied Sciences of El Jadida - Morocco. This system collects all parameters that might influence electrical consumption with Kafka, then it applies Spark libraries to analyze it. The solution allows also electrical energy forecasting using Spark machine learning library and the data persistence using HBase storage system. © 2019 Association for Computing Machinery."
"20th International Conference on Engineering Applications of Neural Networks, EANN 2019",The proceedings contain 46 papers. The special focus in this conference is on Engineering Applications of Neural Networks. The topics include: Enhanced feature selection for facial expression recognition systems with genetic algorithms; Imaging time-series for NILM; learning meaningful sentence embedding based on recursive auto-encoders; pruning extreme wavelets learning machine by automatic relevance determination; students’ performance prediction model using meta-classifier approach; a benchmark framework to evaluate energy disaggregation solutions; a deep network system for simulated autonomous driving using behavioral cloning; a machine hearing framework for real-time streaming analytics using lambda architecture; deep learning and change detection for fall recognition; image classification using deep neural networks: transfer learning and the handling of unknown images; LEARNAE: Distributed and resilient deep neural network training for heterogeneous peer to peer topologies; predicting customer churn using artificial neural network; virtual sensor based on a deep learning approach for estimating efficiency in chillers; canonical correlation analysis framework for the reduction of test time in industrial manufacturing quality tests; convolutional neural network for detection of building contours using multisource spatial data; a meta-multicriteria approach to estimate drought vulnerability based on fuzzy pattern recognition; application of deep learning long short-term memory in energy demand forecasting; bioinspired early prediction of earthquakes inferred by an evolving fuzzy neural network paradigm; enhancing disaster response for hazardous materials using emerging technologies: the role of ai and a research agenda; evolutionary optimization on artificial neural networks for predicting the user’s future semantic location; global minimum depth in edwards-anderson model; signal2Vec: Time series embedding representation.
A machine hearing framework for real-time streaming analytics using lambda architecture,"Disruptions to the earth’s biosphere and to the natural environment stemming from the indiscreet human activity, have caused serious environmental problems which are tantamount to an extended and prolonged ecological crisis. Climate change is clearly reflected in the increase of the global average air and ocean temperatures, in the excessive melting of snow-ice, and in the rise of the global average sea level. One of the most serious impacts of climate change is the complex interaction of species in relation to their corresponding climatic survival factors, which favors the spread of invasive species (INSP). These species constitute a very serious and rapidly deteriorating threat to the natural biodiversity of the native environment, but also to the flora, fauna, and even to the local human population. This research proposes a Machine Hearing (MH) framework for real-time streaming analytics, employing Lambda Architecture (LARC). The hybrid modeling effort is based on timely and advanced Computational Intelligence (COIN) approaches. The Framework for Lambda Architecture Machine Hearing (FLAME_H) uses a combination of batch and streaming data. The FLAME_H applies the EL_GROSEMMARI (Extreme Learning Graph Regularized Online Sequential Multilayer Multiencoder Algorithm) to classify the batch data and the Adaptive Random Forest (ARF) in order to control the data streams in real time. The aim of the proposed framework is the intelligent identification and classification of invasive alien species, based on the sounds they produce. This would contribute to the protection of biodiversity and biosecurity in a certain area. © Springer Nature Switzerland AG 2019."
Toward information system architecture to support predictive maintenance approach,"The prognostic and health management (PHM) approach aims at supporting maintenance operations in order to ensure the functionality of a system. In order to achieve this objective, a PHM approach is composed of a prognostic component, able to send a prognostic of failure, and a component able to give the health status of the system. Nowadays, this approach suffers from a lack of exploitation of the emerging technologies. This article presents a novel architecture for PHM approach able to extract added value from data. This lambda architecture embeds two layers: a speed layer and a storage layer. Thanks to the storage layer, maintenance rules can be applied as well as the result of machine learning algorithms to the speed layer in order to realize the prognostic aspect of the PHM. In addition, the system has to deal with heterogeneous data, which comes with the necessity to handle the big data issues as well as making it interoperable. This is achieved thanks to a service-oriented architecture approach and the use of complex event processing. © Springer Nature Switzerland AG 2019."
FaaStest - Machine learning based cost and performance FaaS optimization,"With the emergence of Function-as-a-Service (FaaS) in the cloud, pay-per-use pricing models became available along with the traditional fixed price model for VMs and increased the complexity of selecting the optimal platform for a given service. We present FaaStest - an autonomous solution for cost and performance optimization of FaaS services by taking a hybrid approach - learning the behavioral patterns of the service and dynamically selecting the optimal platform. Moreover, we combine a prediction based solution for reducing cold starts of FaaS services. Experiments present a reduction of over 50% in cost and over 90% in response time for FaaS calls. © 2019, Springer Nature Switzerland AG."
Towards predicting frailty symptoms through a smart walking stick,A warning sign of frailty is imbalance. Psycho-motor therapists run tests to evaluate the balance deterioration but not often enough to track the rapidly changing condition of the elderly. The proposed system collects fine-grained data from a smart cane and processes them with Machine Learning (ML) techniques. The originality of our proposition lies in its personalization by the elderly biomarkers in ML algorithms. Our experiments indicate that we can observe the orientation of locomotion through the cane as well as recognize characteristics of specific participants ambulation in the uncontrolled scenario. © 2018 IFIP.
Software Architecture Design of the Real- Time Processes Monitoring Platform,Understanding of how business processes are executed in real-life is vitally important for a company. Any process leaves a digital footprint that can be transformed into so-called event logs and analyzed with process mining techniques. A software platform with the purpose of near realtime processes monitoring is implemented. Design of the represented platform is based on the lambda architecture combining online and offline process mining algorithms with advanced analytics based on machine learning. © 2018 IEEE.
Monetizing machine learning: Quickly turn Python ML ideas into web applications on the serverless cloud,"Take your Python machine learning ideas and create serverless web applications accessible by anyone with an Internet connection. Some of the most popular serverless cloud providers are covered in this book-Amazon, Microsoft, Google, and PythonAnywhere. You will work through a series of common Python data science problems in an increasing order of complexity. The practical projects presented in this book are simple, clear, and can be used as templates to jump-start many other types of projects. You will learn to create a web application around numerical or categorical predictions, understand the analysis of text, create powerful and interactive presentations, serve restricted access to data, and leverage web plugins to accept credit card payments and donations. You will get your projects into the hands of the world in no time. Each chapter follows three steps: modeling the right way, designing and developing a local web application, and deploying onto a popular and reliable serverless cloud provider. You can easily jump to or skip particular topics in the book. You also will have access to Jupyter notebooks and code repositories for complete versions of the code covered in the book. What You'll Learn Extend your machine learning models using simple techniques to create compelling and interactive web dashboards Leverage the Flask web framework for rapid prototyping of your Python models and ideas Create dynamic content powered by regression coefficients, logistic regressions, gradient boosting machines, Bayesian classifications, and more Harness the power of TensorFlow by exporting saved models into web applications Create rich web dashboards to handle complex real-time user input with JavaScript and Ajax to yield interactive and tailored content Create dashboards with paywalls to offer subscription-based access Access API data such as Google Maps, OpenWeather, etc. Apply different approaches to make sense of text data and return customized intelligence Build an intuitive and useful recommendation site to add value to users and entice them to keep coming back Utilize the freemium offerings of Google Analytics and analyze the results Take your ideas all the way to your customer's plate using the top serverless cloud providers Who This Book Is For Those with some programming experience with Python, code editing, and access to an interpreter in working order. The book is geared toward entrepreneurs who want to get their ideas onto the web without breaking the bank, small companies without an IT staff, students wanting exposure and training, and for all data science professionals ready to take things to the next level. © 2018 by Manuel Amunategui, Mehdi Roopaei. All rights reserved."
Exploring Serverless Computing for Neural Network Training,"Serverless or functions as a service runtimes have shown significant benefits to efficiency and cost for event-driven cloud applications. Although serverless runtimes are limited to applications requiring lightweight computation and memory, such as machine learning prediction and inference, they have shown improvements on these applications beyond other cloud runtimes. Training deep learning can be both compute and memory intensive. We investigate the use of serverless runtimes while leveraging data parallelism for large models, show the challenges and limitations due to the tightly coupled nature of such models, and propose modifications to the underlying runtime implementations that would mitigate them. For hyperparameter optimization of smaller deep learning models, we show that serverless runtimes can provide significant benefit. © 2018 IEEE."
Machine learning techniques for enhancing maritime surveillance based on GMTI radar and AIS,"Classical maritime surveillance systems are enhanced with disruptive elements comingf om big data and machine learning. Available receiver networks deliver a huge amount of worldwide maritime traffc data. The information includes the position as well as signifcant attributes of all vessels, which are equipped with AIS. The processing of this data lake with modern machine learning and big data techniques offer improved decision support for the user. This is especially the case, when AIS is not available and only sensor information, e.g., GMTI is gathered. New design concepts - e.g. the lambda architecture offer the modular integration of these new assets within existing surveillance systems. © 2018 German Institute of Navigation - DGON."
Implementation of unsupervised k-means clustering algorithm within amazon web services lambda,"This work demonstrates how an unsupervised learning algorithm based on k-Means Clustering with Kaufman Initialization may be implemented effectively as an Amazon Web Services Lambda Function, within their serverless cloud computing service. It emphasizes the need to employ a lean and modular design philosophy, transfer data efficiently between Lambda and DynamoDB, as well as employ Lambda Functions within mobile applications seamlessly and with negligible latency. This work presents a novel application of serverless cloud computing and provides specific examples that will allow readers to develop similar algorithms. The author provides compares the computation speed and cost of machine learning implementations on traditional PC and mobile hardware (running locally) as well as implementations that employ Lambda. © 2018 IEEE."
GPU Enabled Serverless Computing Framework,"A new form of cloud computing, serverless computing, is drawing attention as a new way to design micro-services architectures. In a serverless computing environment, services are developed as service functional units. The function development environment of all serverless computing framework at present is CPU based. In this paper, we propose a GPU-supported serverless computing framework that can deploy services faster than existing serverless computing framework using CPU. Our core approach is to integrate the open source serverless computing framework with NVIDIA-Docker and deploy services based on the GPU support container. We have developed an API that connects the open source framework to the NVIDIA-Docker and commands that enable GPU programming. In our experiments, we measured the performance of the framework in various environments. As a result, developers who want to develop services through the framework can deploy high-performance micro services and developers who want to run deep learning programs without a GPU environment can run code on remote GPUs with little performance degradation. © 2018 IEEE."
SYSTOR 2018 - Proceedings of the 11th ACM International Systems and Storage Conference,"The proceedings contain 23 papers. The topics discussed include: Lerna: parallelizing dependent loops using speculation; chaperone - runtime system for instrumenting applications via partial binary translation; DLIRS: improving low inter-reference recency set cache replacement policy with dynamics; the quick migration of file servers; how to build an insecure system out of perfectly good cryptography; how to best share a big secret; Inkpack: a secure, data-exposure resistant storage system; seamless fail-over for PCIe switched networks; Memomania: from huge to huge-huge pages; collusion in cloud computing auctions; shared cloud object store, governed by permissioned blockchain; space efficient elephant flow detection; Hyplets - multi exception level kernel towards Linux RTOS; towards serverless NFV for 5G media applications; an intelligent recycle bin for smart cities; RestAssured: securing cloud analytics; efficient analytics on encrypted data; accelerating unmodified databases using persistent memory and flash storage tiers; PM aware storage engine for MongoDB; privacy enforcement at a large scale for GDPR compliance; Teechain: reducing storage costs on the blockchain with offline payment channels; applying deep learning to object store caching; and distributed fault-tolerant backup-placement in overloaded wireless sensor networks."
Serving deep learning models in a serverless platform,"Serverless computing has emerged as a compelling paradigm for the development and deployment of a wide range of event based cloud applications. At the same time, cloud providers and enterprise companies are heavily adopting machine learning and Artificial Intelligence to either differentiate themselves, or provide their customers with value added services. In this work we evaluate the suitability of a serverless computing environment for the inferencing of large neural network models. Our experimental evaluations are executed on the AWS Lambda environment using the MxNet deep learning framework. Our experimental results show that while the inferencing latency can be within an acceptable range, longer delays due to cold starts can skew the latency distribution and hence risk violating more stringent SLAs. © 2018 IEEE."
A migration-based approach to execute long-duration multi-cloud serverless functions,"Serverless Computing is emerging as an undeniable paradigm for the deployment of (multi)cloud applications. It is mainly characterized by the use of stateless loosely-coupled functions that are composed together to perform useful actions. This approach, contrarily to monolithic one, makes easier the maintenance and the evolution of the applications, since the functions can be independently revised and reprogrammed. However, one principle in Serverless computing is that function execution should be within a short duration (five minutes max in most Cloud provider platforms), after which the function is abruptly terminated even if it has not completed its task. Moreover, the max duration cannot be extended without a negative effect on the platform performance. This leads to prevent functions requiring longer time from being adopted as Serverless functions. This paper deals with this drawback. It proposes a distributed migration-based approach which promotes the execution of long-duration Serverless functions: each running function that reaches the maximum duration limit is repeatedly transferred to another cloud platform where it is carried on. In this aim, the migration-based system architecture, the migration technique and the migration algorithm are described. The proposed approach use is illustrated by a case study: a generic machine learning application built over the scientific platform ANTDROID. Copyright © by the paper’s authors."
Combining machine learning and semantics for anomaly detection,"The emergence of the Internet of Things and stream processing forces large scale organizations to consider anomaly detection as a key component of their business. Using machine learning to solve such complex use cases is generally a cumbersome, costly, time-consuming and error-prone process. It involves many tasks from data cleansing, to dimension reduction, algorithm selection and fine tuning. It also requires the involvement of various experts such as statisticians, programmers and testers. With RAMSSES, we remove the burden of this pipeline and demonstrate that these tasks can be automated. Our system leverages on a Lambda architecture based on Apache Spark to analyze historical data, perform cleansing and deal with the curse of dimensionality. Then, it identifies the most interesting attributes and uses a continuous semantic query generator executed over streams. The sampled data are processed by self-selected machine learning methods to detect anomalies, an iterative process using end user annotations improves significantly the accuracy of the system. After a description of RAMSSES’s main components, the performance and relevancy of the system are demonstrated via a thorough evaluation over real-world and synthetic datasets. © Springer Nature Switzerland AG 2018."
GPU usage estimation of deep learning training function for serverless computing,"Serverless computing is in the spotlight recently as a new form of cloud computing. And one of the most interested software domain in recent years is deep learning applications. Now serverless computing environment is still just CPU-based. This is because GPU devices are not shared by different processes at the same time unlike CPU. To support deep learning applications in serverless computing with low cost, it is essential to support GPU resource sharing. Nvidia supports MPS with execution resource provisioning on the latest Volta architecture GPU. In order to apply MPS and resource provisioning to GPU-based servlerless computing, it is necessary to know the accurate GPU usage of long-term deep learning functions. In this paper, we propose a technique to predict GPU usage of long-term deep learning training function without watching complete execution of it. The proposed technique is composed of sliding window method and coverage based usage estimation. Through the proposed technique, deep learning training functions can be effectively applied to serverless computing with GPU sharing. © 2018 IADIS Press. All Rights Reserved."
"7th International Congress on Big Data, BigData 2018 Held as Part of the Services Conference Federation, SCF 2018",The proceedings contain 32 papers. The special focus in this conference is on Big Data. The topics include: Tracking happiness of different US cities from tweets; An innovative lambda-architecture-based data warehouse maintenance framework for effective and efficient near-real-time OLAP over big data; the application of machine learning algorithm applied to 3Hs risk assessment; Development of big data multi-VM platform for rapid prototyping of distributed deep learning; developing cost-effective data rescue schemes to tackle disk failures in data centers; on scalability of distributed machine learning with big data on Apache spark; development of a big data platform for analysis of road driving environment using vehicle sensing data and public data; big data framework for finding patterns in multi-market trading data; who’s next: Evaluating attrition with machine learning algorithms and survival analysis; inter-category distribution enhanced feature extraction for efficient text classification; volkswagen’s diesel emission scandal: Analysis of facebook engagement and financial outcomes; leadsRobot: A sales leads generation robot based on big data analytics; Research on the high and new technology development potential of China city clusters based on China’s new OTC market; analysis of activity population and mobility impacts of a new shopping mall using mobile phone bigdata; activity-based traveler analyzer using mobile and socioeconomic bigdata: case study of Seoul in Korea; design and application of a visual system for the supply chain of thermal coal based on big data; big data analytics on Twitter: A systematic review of applications and methods; k-mer counting for genomic big data.
"17th International Conference on Web Engineering, ICWE 2017",The proceedings contain 26 papers. The special focus in this conference is on Web Engineering. The topics include: Towards an Acceptance Testing Approach for Internet of Things Systems; ABC Algorithm for URL Extraction; Towards a UML and IFML Mapping to GraphQL; accessing Government Open Data Through Chatbots; using Ontologies for Official Statistics: The Istat Experience; ontology Population from Raw Text Corpus for Open-Source Intelligence; named Entity Recognition in Twitter Using Images and Text; online Expectation Maximization for Language Characterization of Streaming Text; analysing Cultural Events on Twitter; semantic Discovery in the Web of Things; harvesting Knowledge from Social Networks: Extracting Typed Relationships Among Entities; novel Comment Spam Filtering Method on Youtube: Sentiment Analysis and Personality Recognition; mining Communication Data in a Music Community: A Preliminary Analysis; measuring Personal Branding in Social Media: Towards an Influence Indication Score; big Web Data: Warehousing and Analytics: Recent Trends and Future Challenges; model-Based Development of JavaScript Web Applications; Liquid Web Applications: ICWE2017 Tutorial; challenges When Moving from Monolith to Microservice Architecture; IoT Application Deployment Using Request-Response Pattern with MQTT; wireless Brain-Computer Interface for Wheelchair Control by Using Fast Machine Learning and Real-Time Hyper-Dimensional Classification; case Study: Building a Serverless Messenger Chatbot; four Key Factors to Design a Web of Things Architecture; liquid Transfer of User Identity; engineering Task-Automation Systems for Domain Specificity.
Middleware 2017 - Proceedings of the 2017 International Middleware Conference,The proceedings contain 20 papers. The topics discussed include: HyperDrive: exploring hyperparameters with pop scheduling; sieve: actionable insights from monitored metrics in distributed systems; Rafiki: a middleware for parameter tuning of NoSQL datastores for dynamic metagenomics workloads; Rivulet: a fault-tolerant platform for smart-home applications; binary compatible graphics support in Android for running iOS apps; Sense-Aid: a framework for enabling network as a service for participatory sensing; ORCA: an ORChestration automata for configuring VNFs; improving spark application throughput via memory aware task co-location: a mixture of experts approach; Swayam: distributed autoscaling to meet SLAs of machine learning inference services with resource efficiency; data-driven serverless functions for object storage; a programming model for application-defined multipath TCP scheduling; POLM2: automatic profiling for object lifetime-aware memory management for hotspot big data applications; SPECTRE: supporting consumption policies in window-based parallel complex event processing; efficient covering for top-k filtering in content-based publish/subscribe systems; StreamApprox: approximate computing for stream analytics; X-Search: revisiting private web search using Intel SGX; rectify: black-box intrusion recovery in PaaS Clouds; scheduler activations for interference-resilient SMP virtual machine scheduling; DoubleDecker: a cooperative disk caching framework for derivative clouds; and Ginja: one-dollar cloud-based disaster recovery for databases.
Implementation of a self-adaptive real time recommendation system using spark machine learning libraries,"Real time recommendation systems have become an essential component of e-commerce web applications. With increasing volume and velocity of data handled by these applications, known as the bigdata problem, traditional recommendation systems that analyze data and update models at regular time intervals would not be able to satisfy this requirement. With the evolution of technologies for processing bigdata in real time, it has become fairly easy to implement real time recommendation systems. Stream-computing is a new computing paradigm for handling the velocity attribute of bigdata which makes it possible to develop real time bigdata applications. This paper gives the details of implementation of a real time recommendation system using Apache Spark, a widely used platform for stream computing. This system is implemented for recommending TV channels to viewers in real time. This becomes a challenging task due to continuous changes in the set of available channels and the context dependent preference of viewers. In channel recommendation scenario, characterized by its dynamic nature, volume of data, and tight time constraints, traditional approaches cannot be used. We have implemented a highly scalable TV channel recommendation system optimized for the processing of real-time data streams originating from set-top boxes. The proposed system implements a self-adaptive approach for model building. The system effectively uses distributed processing power of Apache Spark to make recommendations in real time with scalability to meet the real time constraints with increasing load. The Spark Machine Learning Libraries (Spark MLLib) provide several algorithms which were used for developing the proposed recommendation system. The large amount of data in the system is efficiently managed by the data processing method of Lambda Architecture. © 2017 IEEE."
Return of the Runtimes: Rethinking the Language Runtime System for the Cloud 3.0 Era,"The public cloud is moving to a Platform-as-a-Service model where services such as data management, machine learning or image classification are provided by the cloud operator while applications are written in high-level languages and leverage these services. Managed languages such as Java, Python or Scala are widely used in this setting. However, while these languages can increase productivity, they are often associated with problems such as unpredictable garbage collection pauses or warm-up overheads. We argue that the reason for these problems is that current language runtime systems were not initially designed for the cloud setting. To address this, we propose seven tenets for designing future language runtime systems for cloud data centers. We then outline the design of a general substrate for building such runtime systems, based on these seven tenets. © 2017 ACM."
Anticipation and alert system of congestion and accidents in VANET using Big Data analysis for Intelligent Transportation Systems,"Vehicular Networks (VN) have a huge potential to increase roadway safety and traffic efficiency. Big Data analysis can be instrumental in realizing this potential and enhancing the Intelligent Transportation Systems (ITSs). We study the causes of road accidents using big real-time accidents data obtained from Florida Department of Transportation (FDOT) - District 4. The ultimate goal is to prevent or at least decrease traffic accidents and congestions. Our approach is based on dividing the roadway into segments, based on the infrastructure availability and the secondary accidents factors. We design a real-time Big Data system that receives online streamed data from vehicles on the road in addition to real-time average speed data from vehicles detectors on the road side to (1) Provide accurate Estimated Time of Arrival (ETA) using a Linear Regression (LR) model (2) Predict accidents and congestions before they happen using Naive Bayes (NB) and Distributed Random Forest (DRF) classifiers (3) Update ETA if an accident or a congestion takes place by predicting accurate clearance time. To make this system fast, accurate, and reliable we have implemented Lambda Architecture (LA) in our framework because of its speed, scalability, and fault tolerance. Furthermore, we have optimized the efficiency, the speed, and the accuracy of the designed model by securely selecting the most relevant and significant set of features required for the analysis. © 2016 IEEE."
"15th International Conference on Service-Oriented Computing, ICSOC 2017",The proceedings contain 53 papers. The special focus in this conference is on Service-Oriented Computing. The topics include: Confidence-aware reputation bootstrapping in composite service environments; compound trace clustering to generate accurate and simple sub-process models; an approach to modeling and discovering event correlation for service collaboration; energy efficient scheduling of application components via brownout and approximate markov decision process; predicting the available bandwidth on intra cloud network links for deadline constrained workflow scheduling in public clouds; inferring calling relationship based on external observation for microservice architecture; a QoS-aware resource allocation controller for function as a service (FaaS) platform; probabilistic qualitative preference matching in long-term IaaS composition; an embedding based factorization machine approach for web service QoS prediction; RISE: Resolution of identity through similarity establishment on unstructured job descriptions; a deep learning approach for long term QoS-compliant service composition; an artifact-driven approach to monitor business processes through real-world objects; benchFoundry: A benchmarking framework for cloud storage services; automated analysis of cloud offerings for optimal service provisioning; middleware for dynamic upgrade activation and compensations in multi-tenant SaaS; risk-based proactive process adaptation; a debt-aware learning approach for resource adaptations in cloud elasticity management; large-scale and adaptive service composition using deep reinforcement learning; ECHO: An adaptive orchestration platform for hybrid dataflows across cloud and edge; ensuring and assessing architecture conformance to microservice decomposition patterns; social-sensor cloud service for scene reconstruction; polly: A language-based approach for custom change detection of web service data; design and evaluation of a self-service delivery framework.
"Scalability and realtime on big data, MapReduce, NoSQL and spark","Big data platforms strive to achieve scalability and realtime for query processing and complex analytics over “big” and/or “fast” data. In this context, big data warehouses are huge repositories of data to be used in analytics and machine learning. This work discusses models, concepts and approaches to reach scalability and realtime in big data processing and big data warehouses. The main concepts of NoSQL, Parallel Data Management Systems (PDBMS), MapReduce and Spark are reviewed in the context of scalability. The first two offering data management, the last two adding flexible and scalable processing capacities. We also turn our attention to realtime data processing, lambda architecture and its relation with scalability, and we revisit our own recent research on the issue. Three approaches are included that are directly related to realtime and scalability: the use of a realtime component in a data warehouse, parallelized de-normalization for scalability and execution tree sharing for scaling to simultaneous sessions. With these models and technologies we revisit some of the major current solutions for data management and data processing with scalability and realtime capacities. © Springer International Publishing AG 2017."
A conceptual framework for building a mobile services' recommendation engine,"This paper presents a conceptual framework for building a recommendation engine for use in the ubiquitous consumer wireless world (UCWW). The framework is based on the Lambda Architecture and as such provides real-time recommendations at the speed layer and off-time analytical operations at the batch layer. Moreover, at the speed layer, a root server is used for updating the real-time recommendation algorithms and dispatching the processing of users' information to different recommendation servers for load balancing with a consistent hash algorithm. At the batch layer, a number of off-line machine learning algorithms are utilized for items analyzing, user profiling based on raw data, and sending the results to the serving layer. At the end, a decision server formats recommendations for 'best' service instances, which are sent back to users for effecting an always best connected and best served (ABC&S) experience. © 2016 IEEE."
SAMURAI: A batch and streaming context architecture for large-scale intelligent applications and environments,"Over the past decade intelligent environments have grown in sophistication. Many recent paradigm shifts-such as the Internet of Things (IoT), Ambient Assisted Living (AAL), e-health and telemedicine-envision large distributed networks of intelligent devices, applications and services that are sensitive to the presence of people and responsive to their needs. Cutting edge technologies will autonomously and collectively operate on a growing volume of information arriving at ever increasing velocities to transparently and non-intrusively support users during their activities. Especially the escalating variety of information that applications have to deal with is a non-trivial concern. Making sense out of heterogeneous and pervasive streams of sensor events to anticipate and address the needs of users is a ubiquitous challenge that many interactive context-aware applications in intelligent environments frequently face. Furthermore, software solutions that continuously interpret the tasks and contexts of a variety of individuals with different needs are often faced with scalability concerns. We present SAMURAI, a batch and streaming context architecture that integrates and exposes well-known components for complex event processing, machine learning, and knowledge representation. SAMURAI builds upon key concepts of the Lambda architecture and big data enabling technologies to achieve horizontal scalability and responsive interaction with its users. Two application cases validate the feasibility and performance of our context architecture, demonstrating near-linear scalability, flexible elasticity and smooth interaction capabilities. © 2016-IOS Press and the authors. All rights reserved."
Pro spark streaming: The zen of real-time analytics using apache spark,"Learn the right cutting-edge skills and knowledge to leverage Spark Streaming to implement a wide array of real-time, streaming applications. This book walks you through end-to-end real-time application development using real-world applications, data, and code. Taking an application-first approach, each chapter introduces use cases from a specific industry and uses publicly available datasets from that domain to unravel the intricacies of production-grade design and implementation. The domains covered in Pro Spark Streaming include social media, the sharing economy, finance, online advertising, telecommunication, and IoT. In the last few years, Spark has become synonymous with big data processing. DStreams enhance the underlying Spark processing engine to support streaming analysis with a novel micro-batch processing model. Pro Spark Streaming by Zubair Nabi will enable you to become a specialist of latency sensitive applications by leveraging the key features of DStreams, micro-batch processing, and functional programming. To this end, the book includes ready-to-deploy examples and actual code. Pro Spark Streaming will act as the bible of Spark Streaming. What You’ll Learn Discover Spark Streaming application development and best practices Work with the low-level details of discretized streams Optimize production-grade deployments of Spark Streaming via configuration recipes and instrumentation using Graphite, collectd, and Nagios Ingest data from disparate sources including MQTT, Flume, Kafka, Twitter, and a custom HTTP receiver Integrate and couple with HBase, Cassandra, and Redis Take advantage of design patterns for side-effects and maintaining state across the Spark Streaming micro-batch model Implement real-time and scalable ETL using data frames, SparkSQL, Hive, and SparkR Use streaming machine learning, predictive analytics, and recommendations Mesh batch processing with stream processing via the Lambda architecture Who This Book Is For Data scientists, big data experts, BI analysts, and data architects. © 2016 by Zubair Nabi."
An efficient distributed data processing method for smooth environment,"In current times, huge volume of data at a very high velocity gets produced through social media and various sensors in embedded systems that are associated to the internet which causes a very big data problem. These challenging big data's need to beprocessed and stored by traditional Relational Database Management Systems (RDBMS). Due to this motive, the need for new software solutions has occurred for managing the big data in an efficient, scalable and cool way. In this study, an approach to combine the concept of batch processing and stream processing to an end where it can query the data set which also supports adhoc querying with less latency that can be run on any large scale machine learning algorithms for recognizing any interest pattern in the streaming data set was employed. The functionalities of Hadoop ecosystem 's tool HIVE can also be used to produce the results to ad hoc queries, User Defined Functions (UDF) similar to writing a SQL stored procedures in the spark system. An interface with serdes which is serialization and de-serialization that helps us to talk to the standard stream where it can exactly query the dataset are employed. By proposing a new software solution AllJoyn Lambda in which AllJoyn is integrated in the lambda architecture and the prototype implementation of the architecture is done using Apache Hadoop Yarn over Apache Spark Streaming are presented. This study light up the high velocity streaming data set on a database without losing any data from the streaming domain, to support adhoc querying from the data set and to provide a mechanism for fast data processing and analytics using large scale machine learning. This research study highlights the analysis of large scale dataset processing, handling challenges and its comprehensive systematic review. From this study, here it conclude that building a smart environment by using the big data setup platform improves and enhances the results for the smart environment. © Medwell Journals, 2016."
An efficient distributed data processing method for smart environment,"Background/Objectives: In current times, huge volume of data at a very high velocity gets generated through social media and various sensors in embedded systems that are connected to the Internet which causes a very Big data problem. These challenging Big data's need to be processed and stored by traditional Relational Database Management Systems (RDBMS). Due to this reason the need for new software solutions has emerged for managing the Big data in an efficient, scalable and smart way. Methods/Statistical Analysis: In this study, an approach to combine the concept of batch processing and stream processing to an end where we can query the data set which also supports Adhoc Querying with less latency, that can be run on any Large scale Machine Learning Algorithms for recognizing any interest pattern in the streaming data set was employed. The functionalities of Hadoop ecosystem's tool HIVE can also be used to produce the results to Adhoc queries, User Defined Functions (UDF) similar to writing a SQL Stored Procedures in the Spark System. An interface with SerDes which is Serialization and De-serialization that helps us to talk to the standard stream where we can exactly query the dataset are employed. Findings:: By proposing a new software solution AllJoyn Lambda, in which AllJoyn is integrated in the lambda architecture and the prototype implementation of the architecture is done using Apache Hadoop Yarn over Apache Spark Streaming are presented . This study illuminates the high velocity streaming data set on a database without losing any data from the streaming domain, to support Adhoc Querying from the data set and to provide a mechanism for fast data processing and analytics using Large Scale Machine Learning. This paper highlights the analysis of large scale dataset processing, handling challenges, and its comprehensive systematic review. Applications/Improvements: From this study, we conclude that, building a smart environment by using the big data setup platform improves and enhances the results for the smart environment."
Big data machine learning and graph analytics: Current state and future challenges,"Big data machine learning and graph analytics have been widely used in industry, academia and government. Continuous advance in this area is critical to business success, scientific discovery, as well as cybersecurity. In this paper, we present some current projects and propose that next-generation computing systems for big data machine learning and graph analytics need innovative designs in both hardware and software that provide a good match between big data algorithms and the underlying computing and storage resources. © 2014 IEEE."
Big data technology to exploit climate information/consumption models and to predict future behaviours,"This study presents a work in progress of the Smart Home Energy project (SHE), in which tests and simulations have generated a large set of energy consumption data that has been evaluated analytically to define a prediction model for energy consumption, based on automatic machine learning. The SuperDoop Lambda Arquitecture developed by Ingenia for Big Data implementation used in the SHE project allows implementing a service to do predictions massively, developing a personalized home energy knowledge model for each home. These methods and related technology can be used also for other energy consumers, like shops, offices, buildings, industries, electrical vehicles, etc. © Springer International Publishing Switzerland 2014."
